23/01/20 14:22:17.470 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 14:22:17.660 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.1
23/01/20 14:22:17.785 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/20 14:22:17.864 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/01/20 14:22:17.911 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 14:22:17.911 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/01/20 14:22:17.911 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 14:22:17.911 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/01/20 14:22:17.957 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/01/20 14:22:17.973 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/01/20 14:22:17.973 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/01/20 14:22:18.092 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: anthonyp
23/01/20 14:22:18.092 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: anthonyp
23/01/20 14:22:18.092 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/01/20 14:22:18.092 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/01/20 14:22:18.092 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(anthonyp); groups with view permissions: Set(); users  with modify permissions: Set(anthonyp); groups with modify permissions: Set()
23/01/20 14:22:18.385 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 61311.
23/01/20 14:22:18.416 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/01/20 14:22:18.464 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/01/20 14:22:18.495 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/20 14:22:18.495 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/20 14:22:18.510 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/01/20 14:22:18.542 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\blockmgr-d04e682f-b645-4e6c-b335-1877efb68883
23/01/20 14:22:18.558 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
23/01/20 14:22:18.589 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/20 14:22:18.589 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local]. Please check your configured local directories.
23/01/20 14:22:18.879 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/20 14:22:18.964 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/anthonyp/AppData/Local/R/win-library/4.2/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:61311/jars/sparklyr-master-2.12.jar with timestamp 1674253337651
23/01/20 14:22:19.057 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/01/20 14:22:19.057 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/01/20 14:22:19.067 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:61311/jars/sparklyr-master-2.12.jar with timestamp 1674253337651
23/01/20 14:22:19.138 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61311 after 25 ms (0 ms spent in bootstraps)
23/01/20 14:22:19.146 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:61311/jars/sparklyr-master-2.12.jar to C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8831d77a-e9b1-41ef-8e9b-2933156d1f6e\userFiles-589570bd-6aaf-45ff-a35c-dbfdda3a81fd\fetchFileTemp5182212395673080279.tmp
23/01/20 14:22:19.273 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local/spark-8831d77a-e9b1-41ef-8e9b-2933156d1f6e/userFiles-589570bd-6aaf-45ff-a35c-dbfdda3a81fd/sparklyr-master-2.12.jar to class loader
23/01/20 14:22:19.281 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61359.
23/01/20 14:22:19.281 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:61359
23/01/20 14:22:19.296 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/20 14:22:19.296 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61359, None)
23/01/20 14:22:19.296 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61359 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 61359, None)
23/01/20 14:22:19.312 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61359, None)
23/01/20 14:22:19.312 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61359, None)
23/01/20 14:22:19.762 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive') to the value of spark.sql.warehouse.dir.
23/01/20 14:22:19.778 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive'.
23/01/20 14:22:24.092 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/01/20 14:22:24.261 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 14:22:24.805 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive
23/01/20 14:22:25.133 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 14:22:25.133 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 14:22:25.133 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 14:22:25.189 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/01/20 14:22:25.392 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/01/20 14:22:25.392 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/01/20 14:22:27.094 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/01/20 14:22:29.162 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 14:22:29.162 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/01/20 14:22:29.234 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/01/20 14:22:29.243 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.229
23/01/20 14:22:29.259 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/01/20 14:22:29.446 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/01/20 14:22:29.454 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/01/20 14:22:29.510 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/01/20 14:22:29.647 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:22:29.647 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:22:29.672 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/01/20 14:22:29.672 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/01/20 14:22:29.680 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/01/20 14:22:29.680 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:22:29.680 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:22:29.680 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:22:29.680 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:22:29.688 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 14:22:29.688 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 14:22:30.218 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:22:30.218 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:22:30.226 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:22:30.226 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:22:30.226 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 14:22:30.226 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 14:26:44.698 Thread-1 INFO SparkContext: Invoking stop() from shutdown hook
23/01/20 14:26:44.738 Thread-1 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/01/20 14:26:44.842 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/20 14:26:44.874 Thread-1 INFO MemoryStore: MemoryStore cleared
23/01/20 14:26:44.874 Thread-1 INFO BlockManager: BlockManager stopped
23/01/20 14:26:44.898 Thread-1 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/20 14:26:44.911 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/20 14:26:44.970 Thread-1 INFO SparkContext: Successfully stopped SparkContext
23/01/20 14:26:44.970 Thread-1 INFO ShutdownHookManager: Shutdown hook called
23/01/20 14:26:44.978 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\Temp\spark-5cc7eafc-251b-4b85-90f1-a5b14d383207
23/01/20 14:26:44.994 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8831d77a-e9b1-41ef-8e9b-2933156d1f6e
23/01/20 14:49:24.825 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 14:49:24.958 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.1
23/01/20 14:49:25.020 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/20 14:49:25.070 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/01/20 14:49:25.095 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 14:49:25.095 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/01/20 14:49:25.095 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 14:49:25.095 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/01/20 14:49:25.115 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/01/20 14:49:25.125 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/01/20 14:49:25.130 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/01/20 14:49:25.196 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: anthonyp
23/01/20 14:49:25.196 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: anthonyp
23/01/20 14:49:25.196 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/01/20 14:49:25.196 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/01/20 14:49:25.196 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(anthonyp); groups with view permissions: Set(); users  with modify permissions: Set(anthonyp); groups with modify permissions: Set()
23/01/20 14:49:25.335 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 63600.
23/01/20 14:49:25.363 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/01/20 14:49:25.385 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/01/20 14:49:25.407 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/20 14:49:25.407 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/20 14:49:25.414 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/01/20 14:49:25.430 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\blockmgr-5cd458d1-39df-46ac-bdad-8f4ee28587d0
23/01/20 14:49:25.450 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
23/01/20 14:49:25.462 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/20 14:49:25.465 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local]. Please check your configured local directories.
23/01/20 14:49:25.625 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/20 14:49:25.668 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/anthonyp/AppData/Local/R/win-library/4.2/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:63600/jars/sparklyr-master-2.12.jar with timestamp 1674254964952
23/01/20 14:49:25.737 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/01/20 14:49:25.743 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/01/20 14:49:25.747 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:63600/jars/sparklyr-master-2.12.jar with timestamp 1674254964952
23/01/20 14:49:25.785 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63600 after 13 ms (0 ms spent in bootstraps)
23/01/20 14:49:25.790 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:63600/jars/sparklyr-master-2.12.jar to C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-00e4b117-f23c-49b3-900d-2a7b97a1673c\userFiles-aa8a424f-ac82-466a-bce7-0ee452714868\fetchFileTemp857204386043123705.tmp
23/01/20 14:49:25.875 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local/spark-00e4b117-f23c-49b3-900d-2a7b97a1673c/userFiles-aa8a424f-ac82-466a-bce7-0ee452714868/sparklyr-master-2.12.jar to class loader
23/01/20 14:49:25.895 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63648.
23/01/20 14:49:25.895 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:63648
23/01/20 14:49:25.895 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/20 14:49:25.908 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63648, None)
23/01/20 14:49:25.915 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63648 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 63648, None)
23/01/20 14:49:25.915 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63648, None)
23/01/20 14:49:25.922 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63648, None)
23/01/20 14:49:26.205 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive') to the value of spark.sql.warehouse.dir.
23/01/20 14:49:26.208 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive'.
23/01/20 14:49:28.893 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/01/20 14:49:29.002 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 14:49:29.315 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive
23/01/20 14:49:29.527 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 14:49:29.527 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 14:49:29.528 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 14:49:29.560 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/01/20 14:49:29.663 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/01/20 14:49:29.665 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/01/20 14:49:30.480 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/01/20 14:49:31.610 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 14:49:31.610 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/01/20 14:49:31.655 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/01/20 14:49:31.655 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.229
23/01/20 14:49:31.665 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/01/20 14:49:31.775 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/01/20 14:49:31.775 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/01/20 14:49:31.817 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/01/20 14:49:31.880 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:49:31.881 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:49:31.894 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 14:49:31.897 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 14:49:32.176 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:49:32.176 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:49:32.178 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 14:49:32.178 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 14:49:32.178 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 14:49:32.179 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:10:40.098 Thread-1 INFO SparkContext: Invoking stop() from shutdown hook
23/01/20 15:10:40.109 Thread-1 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/01/20 15:10:40.119 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/20 15:10:40.127 Thread-1 INFO MemoryStore: MemoryStore cleared
23/01/20 15:10:40.127 Thread-1 INFO BlockManager: BlockManager stopped
23/01/20 15:10:40.135 Thread-1 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/20 15:10:40.138 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/20 15:10:40.143 Thread-1 INFO SparkContext: Successfully stopped SparkContext
23/01/20 15:10:40.144 Thread-1 INFO ShutdownHookManager: Shutdown hook called
23/01/20 15:10:40.144 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-00e4b117-f23c-49b3-900d-2a7b97a1673c
23/01/20 15:10:40.144 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\Temp\spark-1c36fb39-ec8c-4f4d-8b65-b77ae52f5b6d
23/01/20 15:25:45.592 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:25:45.722 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.1
23/01/20 15:25:45.792 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/20 15:25:45.842 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/01/20 15:25:45.867 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:25:45.867 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/01/20 15:25:45.867 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:25:45.867 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/01/20 15:25:45.887 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/01/20 15:25:45.903 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/01/20 15:25:45.903 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/01/20 15:25:45.972 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: anthonyp
23/01/20 15:25:45.972 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: anthonyp
23/01/20 15:25:45.972 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/01/20 15:25:45.975 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/01/20 15:25:45.975 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(anthonyp); groups with view permissions: Set(); users  with modify permissions: Set(anthonyp); groups with modify permissions: Set()
23/01/20 15:25:46.092 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 65324.
23/01/20 15:25:46.122 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/01/20 15:25:46.152 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/01/20 15:25:46.172 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/20 15:25:46.172 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/20 15:25:46.176 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/01/20 15:25:46.195 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\blockmgr-c3d8d42c-6af1-4f9e-a096-9b74a117fb91
23/01/20 15:25:46.212 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
23/01/20 15:25:46.224 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/20 15:25:46.224 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local]. Please check your configured local directories.
23/01/20 15:25:46.398 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/20 15:25:46.446 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/anthonyp/AppData/Local/R/win-library/4.2/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:65324/jars/sparklyr-master-2.12.jar with timestamp 1674257145722
23/01/20 15:25:46.502 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/01/20 15:25:46.512 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/01/20 15:25:46.517 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:65324/jars/sparklyr-master-2.12.jar with timestamp 1674257145722
23/01/20 15:25:46.557 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:65324 after 13 ms (0 ms spent in bootstraps)
23/01/20 15:25:46.562 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:65324/jars/sparklyr-master-2.12.jar to C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618\fetchFileTemp6171535085730236592.tmp
23/01/20 15:25:46.654 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local/spark-8ff4990a-904d-4df6-90e1-cbc22629588b/userFiles-95320a9e-480b-4af5-b806-7bc72a495618/sparklyr-master-2.12.jar to class loader
23/01/20 15:25:46.672 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65372.
23/01/20 15:25:46.676 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:65372
23/01/20 15:25:46.676 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/20 15:25:46.682 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 65372, None)
23/01/20 15:25:46.686 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:65372 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 65372, None)
23/01/20 15:25:46.686 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 65372, None)
23/01/20 15:25:46.686 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 65372, None)
23/01/20 15:25:46.982 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive') to the value of spark.sql.warehouse.dir.
23/01/20 15:25:46.984 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive'.
23/01/20 15:25:49.729 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/01/20 15:25:49.860 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:25:50.192 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive
23/01/20 15:25:50.409 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 15:25:50.410 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 15:25:50.410 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 15:25:50.453 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/01/20 15:25:50.562 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/01/20 15:25:50.562 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/01/20 15:25:51.422 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/01/20 15:25:52.566 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 15:25:52.572 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/01/20 15:25:52.612 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/01/20 15:25:52.612 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.229
23/01/20 15:25:52.628 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/01/20 15:25:52.742 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/01/20 15:25:52.742 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/01/20 15:25:52.785 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/01/20 15:25:52.859 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:25:52.862 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:25:52.881 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/01/20 15:25:52.882 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/01/20 15:25:52.883 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/01/20 15:25:52.884 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:25:52.884 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:25:52.887 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:25:52.887 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:25:52.889 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:25:52.889 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:25:53.172 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:25:53.175 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:25:53.176 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:25:53.176 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:25:53.177 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:25:53.177 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:30:51.702 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:30:51.702 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:30:51.706 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:30:51.706 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:30:51.706 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:30:51.706 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:30:52.139 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 127.5846 ms
23/01/20 15:30:52.282 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:30:52.292 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.007987 s
23/01/20 15:30:52.794 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2032 ms
23/01/20 15:30:52.810 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:30:52.820 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:30:52.820 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/01/20 15:30:52.821 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:30:52.821 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:30:52.825 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/01/20 15:30:52.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:30:52.917 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:30:52.919 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:30:52.922 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
23/01/20 15:30:52.935 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:30:52.936 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/01/20 15:30:52.988 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:30:53.003 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/01/20 15:30:53.211 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1361 bytes result sent to driver
23/01/20 15:30:53.218 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 246 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:30:53.221 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/01/20 15:30:53.226 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.390 s
23/01/20 15:30:53.231 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:30:53.231 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/01/20 15:30:53.231 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.422124 s
23/01/20 15:30:53.258 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.7723 ms
23/01/20 15:30:53.401 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:30:53.401 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:30:53.401 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/01/20 15:30:53.401 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:30:53.402 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:30:53.403 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/01/20 15:30:53.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:30:53.406 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:30:53.406 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:30:53.407 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
23/01/20 15:30:53.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:30:53.408 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/01/20 15:30:53.409 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:30:53.410 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/01/20 15:30:53.413 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1275 bytes result sent to driver
23/01/20 15:30:53.414 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:30:53.415 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/01/20 15:30:53.415 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.012 s
23/01/20 15:30:53.416 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:30:53.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/01/20 15:30:53.416 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.015434 s
23/01/20 15:30:56.141 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:30:56.169 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:30:56.171 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 126.3 MiB, free 786.0 MiB)
23/01/20 15:30:56.291 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 782.0 MiB)
23/01/20 15:30:56.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 908.3 MiB)
23/01/20 15:30:56.291 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 778.0 MiB)
23/01/20 15:30:56.304 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece1 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 904.3 MiB)
23/01/20 15:30:56.304 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 774.0 MiB)
23/01/20 15:30:56.308 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece2 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 900.3 MiB)
23/01/20 15:30:56.309 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 770.0 MiB)
23/01/20 15:30:56.311 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece3 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 896.3 MiB)
23/01/20 15:30:56.314 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece4 stored as bytes in memory (estimated size 3.9 MiB, free 766.1 MiB)
23/01/20 15:30:56.314 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece4 in memory on 127.0.0.1:65372 (size: 3.9 MiB, free: 892.4 MiB)
23/01/20 15:30:56.315 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 2 from broadcast at workerhelper.scala:104
23/01/20 15:30:56.316 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 40.0 B, free 766.1 MiB)
23/01/20 15:30:56.317 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 69.0 B, free 766.1 MiB)
23/01/20 15:30:56.317 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:65372 (size: 69.0 B, free: 892.4 MiB)
23/01/20 15:30:56.318 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 3 from broadcast at workerhelper.scala:105
23/01/20 15:30:56.318 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 248.0 B, free 766.1 MiB)
23/01/20 15:30:56.320 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 219.0 B, free 766.1 MiB)
23/01/20 15:30:56.321 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:65372 (size: 219.0 B, free: 892.4 MiB)
23/01/20 15:30:56.321 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 4 from broadcast at workerhelper.scala:106
23/01/20 15:30:56.322 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1320.0 B, free 766.1 MiB)
23/01/20 15:30:56.323 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 501.0 B, free 766.1 MiB)
23/01/20 15:30:56.324 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:65372 (size: 501.0 B, free: 892.4 MiB)
23/01/20 15:30:56.324 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 5 from broadcast at workerhelper.scala:107
23/01/20 15:30:56.324 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1928.0 B, free 766.1 MiB)
23/01/20 15:30:56.326 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1033.0 B, free 766.1 MiB)
23/01/20 15:30:56.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:65372 (size: 1033.0 B, free: 892.4 MiB)
23/01/20 15:30:56.327 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 6 from broadcast at workerhelper.scala:108
23/01/20 15:30:56.413 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:30:56.414 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:30:56.414 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/01/20 15:30:56.414 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:30:56.414 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:30:56.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
23/01/20 15:30:56.418 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KiB, free 766.1 MiB)
23/01/20 15:30:56.419 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 766.1 MiB)
23/01/20 15:30:56.419 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 892.4 MiB)
23/01/20 15:30:56.421 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
23/01/20 15:30:56.421 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:30:56.421 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/01/20 15:30:56.422 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.422 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/01/20 15:30:56.427 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1318 bytes result sent to driver
23/01/20 15:30:56.429 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 7 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:30:56.429 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/01/20 15:30:56.430 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.014 s
23/01/20 15:30:56.430 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:30:56.430 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/01/20 15:30:56.431 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.016864 s
23/01/20 15:30:56.709 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.0757 ms
23/01/20 15:30:56.741 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.2782 ms
23/01/20 15:30:56.751 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.5129 ms
23/01/20 15:30:56.812 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 26 (sql at <unknown>:0) as input to shuffle 0
23/01/20 15:30:56.812 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:30:56.812 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (sql at <unknown>:0)
23/01/20 15:30:56.812 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:30:56.819 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:30:56.821 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0), which has no missing parents
23/01/20 15:30:56.851 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.8 KiB, free 766.1 MiB)
23/01/20 15:30:56.851 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 766.1 MiB)
23/01/20 15:30:56.851 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:65372 (size: 11.8 KiB, free: 892.4 MiB)
23/01/20 15:30:56.851 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
23/01/20 15:30:56.851 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:30:56.851 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
23/01/20 15:30:56.861 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:30:56.861 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.867 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.867 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 3009944 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9) (127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 2977439 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10) (127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 3013382 bytes) taskResourceAssignments Map()
23/01/20 15:30:56.881 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/01/20 15:30:56.881 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
23/01/20 15:30:56.881 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
23/01/20 15:30:56.883 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
23/01/20 15:30:56.883 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO Executor: Running task 5.0 in stage 3.0 (TID 8)
23/01/20 15:30:56.883 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO Executor: Running task 7.0 in stage 3.0 (TID 10)
23/01/20 15:30:56.883 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO Executor: Running task 6.0 in stage 3.0 (TID 9)
23/01/20 15:30:56.883 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
23/01/20 15:30:57.004 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 2.8 MiB, free 763.2 MiB)
23/01/20 15:30:57.008 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 889.6 MiB)
23/01/20 15:30:57.008 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO MemoryStore: Block rdd_13_6 stored as values in memory (estimated size 2.8 MiB, free 760.4 MiB)
23/01/20 15:30:57.008 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 2.8 MiB, free 754.8 MiB)
23/01/20 15:30:57.008 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 2.8 MiB, free 754.8 MiB)
23/01/20 15:30:57.011 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_6 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 886.7 MiB)
23/01/20 15:30:57.011 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 883.9 MiB)
23/01/20 15:30:57.011 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 881.1 MiB)
23/01/20 15:30:57.011 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 2.8 MiB, free 751.9 MiB)
23/01/20 15:30:57.011 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_4 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 878.2 MiB)
23/01/20 15:30:57.011 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 2.8 MiB, free 749.1 MiB)
23/01/20 15:30:57.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 875.4 MiB)
23/01/20 15:30:57.036 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO MemoryStore: Block rdd_13_7 stored as values in memory (estimated size 2.8 MiB, free 746.3 MiB)
23/01/20 15:30:57.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_7 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 872.6 MiB)
23/01/20 15:30:57.041 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO MemoryStore: Block rdd_13_5 stored as values in memory (estimated size 2.8 MiB, free 743.4 MiB)
23/01/20 15:30:57.041 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_5 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 869.7 MiB)
23/01/20 15:30:57.041 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO CodeGenerator: Code generated in 6.2758 ms
23/01/20 15:30:57.071 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO CodeGenerator: Code generated in 18.6108 ms
23/01/20 15:30:57.071 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO CodeGenerator: Code generated in 5.93 ms
23/01/20 15:31:04.092 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 869.7 MiB)
23/01/20 15:31:07.671 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Putting block rdd_21_5 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:31:07.671 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Putting block rdd_21_4 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:31:07.671 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Block rdd_21_4 could not be removed as it was not found on disk or in memory
23/01/20 15:31:07.671 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Block rdd_21_5 could not be removed as it was not found on disk or in memory
23/01/20 15:31:07.681 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) ERROR Executor: Exception in task 5.0 in stage 3.0 (TID 8)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:31:07.681 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 7)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:31:07.686 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Putting block rdd_21_7 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:31:07.687 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Block rdd_21_7 could not be removed as it was not found on disk or in memory
23/01/20 15:31:07.687 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) ERROR Executor: Exception in task 7.0 in stage 3.0 (TID 10)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:31:07.691 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Putting block rdd_21_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:31:07.691 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Block rdd_21_3 could not be removed as it was not found on disk or in memory
23/01/20 15:31:07.691 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) ERROR Executor: Exception in task 3.0 in stage 3.0 (TID 6)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:31:07.703 task-result-getter-3 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 7) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:31:07.703 task-result-getter-3 ERROR TaskSetManager: Task 4 in stage 3.0 failed 1 times; aborting job
23/01/20 15:31:07.703 task-result-getter-2 INFO TaskSetManager: Lost task 7.0 in stage 3.0 (TID 10) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 1]
23/01/20 15:31:07.703 task-result-getter-1 INFO TaskSetManager: Lost task 5.0 in stage 3.0 (TID 8) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 2]
23/01/20 15:31:07.703 task-result-getter-0 INFO TaskSetManager: Lost task 3.0 in stage 3.0 (TID 6) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 3]
23/01/20 15:31:07.703 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 3
23/01/20 15:31:07.703 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage cancelled
23/01/20 15:31:07.711 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 6.0 in stage 3.0 (TID 9), reason: Stage cancelled
23/01/20 15:31:07.711 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 2.0 in stage 3.0 (TID 5), reason: Stage cancelled
23/01/20 15:31:07.711 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 0.0 in stage 3.0 (TID 3), reason: Stage cancelled
23/01/20 15:31:07.711 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 1.0 in stage 3.0 (TID 4), reason: Stage cancelled
23/01/20 15:31:07.711 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 3 was cancelled
23/01/20 15:31:07.711 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) failed in 10.890 s due to Job aborted due to stage failure: Task 4 in stage 3.0 failed 1 times, most recent failure: Lost task 4.0 in stage 3.0 (TID 7) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:38:23.238 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:38:23.285 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.2797 ms
23/01/20 15:38:23.317 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.6656 ms
23/01/20 15:38:23.348 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 2 output partitions
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[29] at collect at utils.scala:26), which has no missing parents
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.1 KiB, free 743.4 MiB)
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 743.4 MiB)
23/01/20 15:38:23.348 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:65372 (size: 3.7 KiB, free: 869.7 MiB)
23/01/20 15:38:23.348 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
23/01/20 15:38:23.363 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[29] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
23/01/20 15:38:23.363 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0
23/01/20 15:38:23.363 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:38:23.363 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 12) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:38:23.363 Executor task launch worker for task 0.0 in stage 4.0 (TID 11) INFO Executor: Running task 0.0 in stage 4.0 (TID 11)
23/01/20 15:38:23.363 Executor task launch worker for task 1.0 in stage 4.0 (TID 12) INFO Executor: Running task 1.0 in stage 4.0 (TID 12)
23/01/20 15:38:23.380 Executor task launch worker for task 1.0 in stage 4.0 (TID 12) INFO Executor: Finished task 1.0 in stage 4.0 (TID 12). 1382 bytes result sent to driver
23/01/20 15:38:23.380 Executor task launch worker for task 0.0 in stage 4.0 (TID 11) INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 1382 bytes result sent to driver
23/01/20 15:38:23.381 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 12) in 18 ms on 127.0.0.1 (executor driver) (1/2)
23/01/20 15:38:23.381 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 18 ms on 127.0.0.1 (executor driver) (2/2)
23/01/20 15:38:23.382 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/01/20 15:38:23.382 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.034 s
23/01/20 15:38:23.383 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:38:23.383 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/01/20 15:38:23.383 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.028885 s
23/01/20 15:38:23.392 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.3834 ms
23/01/20 15:38:23.641 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:65372 in memory (size: 3.7 KiB, free: 869.7 MiB)
23/01/20 15:38:23.752 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:38:23.752 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:38:23.752 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
23/01/20 15:38:23.752 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:38:23.753 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:38:23.754 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
23/01/20 15:38:23.756 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KiB, free 743.4 MiB)
23/01/20 15:38:23.758 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 743.4 MiB)
23/01/20 15:38:23.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 869.7 MiB)
23/01/20 15:38:23.760 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
23/01/20 15:38:23.760 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:38:23.760 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/01/20 15:38:23.762 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 13) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:38:23.763 Executor task launch worker for task 0.0 in stage 5.0 (TID 13) INFO Executor: Running task 0.0 in stage 5.0 (TID 13)
23/01/20 15:38:23.766 Executor task launch worker for task 0.0 in stage 5.0 (TID 13) INFO Executor: Finished task 0.0 in stage 5.0 (TID 13). 1275 bytes result sent to driver
23/01/20 15:38:23.767 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 13) in 6 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:38:23.767 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/01/20 15:38:23.767 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.013 s
23/01/20 15:38:23.768 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:38:23.768 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/01/20 15:38:23.768 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.016106 s
23/01/20 15:38:23.868 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:38:23.869 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:38:23.869 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
23/01/20 15:38:23.869 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:38:23.869 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:38:23.870 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
23/01/20 15:38:23.872 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KiB, free 743.4 MiB)
23/01/20 15:38:23.873 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 743.4 MiB)
23/01/20 15:38:23.874 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 869.7 MiB)
23/01/20 15:38:23.874 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
23/01/20 15:38:23.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:38:23.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/01/20 15:38:23.876 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 14) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:38:23.877 Executor task launch worker for task 0.0 in stage 6.0 (TID 14) INFO Executor: Running task 0.0 in stage 6.0 (TID 14)
23/01/20 15:38:23.880 Executor task launch worker for task 0.0 in stage 6.0 (TID 14) INFO Executor: Finished task 0.0 in stage 6.0 (TID 14). 1318 bytes result sent to driver
23/01/20 15:38:23.880 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 14) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:38:23.880 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/01/20 15:38:23.881 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.010 s
23/01/20 15:38:23.881 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:38:23.881 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/01/20 15:38:23.881 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0.013206 s
23/01/20 15:38:25.903 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 126.3 MiB, free 617.2 MiB)
23/01/20 15:38:25.985 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 613.2 MiB)
23/01/20 15:38:25.985 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 865.7 MiB)
23/01/20 15:38:25.985 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 609.2 MiB)
23/01/20 15:38:25.985 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece1 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 861.7 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 605.2 MiB)
23/01/20 15:38:26.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece2 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 857.7 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 601.2 MiB)
23/01/20 15:38:26.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece3 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 853.7 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece4 stored as bytes in memory (estimated size 3.9 MiB, free 597.3 MiB)
23/01/20 15:38:26.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece4 in memory on 127.0.0.1:65372 (size: 3.9 MiB, free: 849.8 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at workerhelper.scala:104
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 40.0 B, free 597.3 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 69.0 B, free 597.3 MiB)
23/01/20 15:38:26.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:65372 (size: 69.0 B, free: 849.8 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from broadcast at workerhelper.scala:105
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 248.0 B, free 597.3 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 219.0 B, free 597.3 MiB)
23/01/20 15:38:26.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:65372 (size: 219.0 B, free: 849.8 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 14 from broadcast at workerhelper.scala:106
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1320.0 B, free 597.3 MiB)
23/01/20 15:38:26.000 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 501.0 B, free 597.3 MiB)
23/01/20 15:38:26.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:65372 (size: 501.0 B, free: 849.8 MiB)
23/01/20 15:38:26.014 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from broadcast at workerhelper.scala:107
23/01/20 15:38:26.014 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 1928.0 B, free 597.2 MiB)
23/01/20 15:38:26.014 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1033.0 B, free 597.2 MiB)
23/01/20 15:38:26.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:65372 (size: 1033.0 B, free: 849.8 MiB)
23/01/20 15:38:26.016 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 16 from broadcast at workerhelper.scala:108
23/01/20 15:38:26.074 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:38:26.074 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:38:26.074 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
23/01/20 15:38:26.074 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:38:26.074 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[36] at collect at utils.scala:26), which has no missing parents
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KiB, free 597.2 MiB)
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 597.2 MiB)
23/01/20 15:38:26.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 849.8 MiB)
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[36] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/01/20 15:38:26.089 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 15) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:38:26.089 Executor task launch worker for task 0.0 in stage 7.0 (TID 15) INFO Executor: Running task 0.0 in stage 7.0 (TID 15)
23/01/20 15:38:26.089 Executor task launch worker for task 0.0 in stage 7.0 (TID 15) INFO Executor: Finished task 0.0 in stage 7.0 (TID 15). 1275 bytes result sent to driver
23/01/20 15:38:26.089 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 15) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:38:26.089 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.000 s
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:38:26.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/01/20 15:38:26.089 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.010986 s
23/01/20 15:38:26.152 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 52 (sql at <unknown>:0) as input to shuffle 1
23/01/20 15:38:26.152 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 9 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:38:26.152 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 8 (sql at <unknown>:0)
23/01/20 15:38:26.152 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:38:26.152 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:38:26.167 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[52] at sql at <unknown>:0), which has no missing parents
23/01/20 15:38:26.183 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 29.8 KiB, free 597.2 MiB)
23/01/20 15:38:26.183 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 597.2 MiB)
23/01/20 15:38:26.183 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:65372 (size: 11.8 KiB, free: 849.8 MiB)
23/01/20 15:38:26.183 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
23/01/20 15:38:26.183 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[52] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:38:26.183 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
23/01/20 15:38:26.183 dispatcher-event-loop-5 WARN TaskSetManager: Stage 8 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:38:26.199 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 16) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:38:26.199 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 17) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:38:26.199 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 18) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:38:26.199 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 19) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:38:26.199 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO Executor: Running task 0.0 in stage 8.0 (TID 16)
23/01/20 15:38:26.199 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) INFO Executor: Running task 1.0 in stage 8.0 (TID 17)
23/01/20 15:38:26.199 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) INFO Executor: Running task 2.0 in stage 8.0 (TID 18)
23/01/20 15:38:26.199 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) INFO Executor: Running task 3.0 in stage 8.0 (TID 19)
23/01/20 15:38:26.230 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 2.8 MiB, free 594.4 MiB)
23/01/20 15:38:26.230 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) INFO MemoryStore: Block rdd_39_1 stored as values in memory (estimated size 2.8 MiB, free 591.6 MiB)
23/01/20 15:38:26.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_0 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 847.0 MiB)
23/01/20 15:38:26.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_1 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 844.2 MiB)
23/01/20 15:38:26.230 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) INFO MemoryStore: Block rdd_39_2 stored as values in memory (estimated size 2.8 MiB, free 588.7 MiB)
23/01/20 15:38:26.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_2 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 841.4 MiB)
23/01/20 15:38:26.230 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) INFO MemoryStore: Block rdd_39_3 stored as values in memory (estimated size 2.8 MiB, free 585.9 MiB)
23/01/20 15:38:26.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 841.4 MiB)
23/01/20 15:38:26.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_3 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 838.5 MiB)
23/01/20 15:38:26.246 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 838.5 MiB)
23/01/20 15:38:26.246 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 838.5 MiB)
23/01/20 15:38:31.897 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) WARN BlockManager: Putting block rdd_47_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:38:31.897 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) WARN BlockManager: Block rdd_47_2 could not be removed as it was not found on disk or in memory
23/01/20 15:38:31.899 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) ERROR Executor: Exception in task 2.0 in stage 8.0 (TID 18)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:38:31.902 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 20) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:38:31.902 task-result-getter-2 WARN TaskSetManager: Lost task 2.0 in stage 8.0 (TID 18) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:38:31.903 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) INFO Executor: Running task 4.0 in stage 8.0 (TID 20)
23/01/20 15:38:31.903 task-result-getter-2 ERROR TaskSetManager: Task 2 in stage 8.0 failed 1 times; aborting job
23/01/20 15:38:31.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 8
23/01/20 15:38:31.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage cancelled
23/01/20 15:38:31.904 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 8 was cancelled
23/01/20 15:38:31.904 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 8 (sql at <unknown>:0) failed in 5.737 s due to Job aborted due to stage failure: Task 2 in stage 8.0 failed 1 times, most recent failure: Lost task 2.0 in stage 8.0 (TID 18) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:38:31.904 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 3.0 in stage 8.0 (TID 19), reason: Stage cancelled
23/01/20 15:38:31.905 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 0.0 in stage 8.0 (TID 16), reason: Stage cancelled
23/01/20 15:38:31.905 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 4.0 in stage 8.0 (TID 20), reason: Stage cancelled
23/01/20 15:38:31.905 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 1.0 in stage 8.0 (TID 17), reason: Stage cancelled
23/01/20 15:38:31.906 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) INFO Executor: Executor killed task 4.0 in stage 8.0 (TID 20), reason: Stage cancelled
23/01/20 15:38:31.906 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) WARN BlockManager: Putting block rdd_47_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:38:31.906 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) WARN BlockManager: Block rdd_47_3 could not be removed as it was not found on disk or in memory
23/01/20 15:38:31.906 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) INFO Executor: Executor interrupted and killed task 3.0 in stage 8.0 (TID 19), reason: Stage cancelled
23/01/20 15:38:31.906 task-result-getter-1 WARN TaskSetManager: Lost task 4.0 in stage 8.0 (TID 20) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:38:31.906 task-result-getter-0 WARN TaskSetManager: Lost task 3.0 in stage 8.0 (TID 19) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:38:31.906 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) WARN BlockManager: Putting block rdd_47_0 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:38:31.906 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) WARN BlockManager: Block rdd_47_0 could not be removed as it was not found on disk or in memory
23/01/20 15:38:31.906 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) WARN BlockManager: Putting block rdd_47_1 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:38:31.906 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) WARN BlockManager: Block rdd_47_1 could not be removed as it was not found on disk or in memory
23/01/20 15:38:31.906 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO Executor: Executor interrupted and killed task 0.0 in stage 8.0 (TID 16), reason: Stage cancelled
23/01/20 15:38:31.906 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) INFO Executor: Executor interrupted and killed task 1.0 in stage 8.0 (TID 17), reason: Stage cancelled
23/01/20 15:38:31.922 task-result-getter-3 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 16) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:38:31.922 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/01/20 15:38:31.922 task-result-getter-2 WARN TaskSetManager: Lost task 1.0 in stage 8.0 (TID 17) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:38:31.922 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:42:49.743 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:42:49.791 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 4 output partitions
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[55] at collect at utils.scala:26), which has no missing parents
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.1 KiB, free 585.9 MiB)
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 585.9 MiB)
23/01/20 15:42:49.791 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:65372 (size: 3.7 KiB, free: 838.5 MiB)
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[55] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
23/01/20 15:42:49.791 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
23/01/20 15:42:49.791 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:42:49.791 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 22) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:42:49.791 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 23) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:42:49.791 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 24) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:42:49.791 Executor task launch worker for task 2.0 in stage 9.0 (TID 23) INFO Executor: Running task 2.0 in stage 9.0 (TID 23)
23/01/20 15:42:49.791 Executor task launch worker for task 0.0 in stage 9.0 (TID 21) INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
23/01/20 15:42:49.791 Executor task launch worker for task 3.0 in stage 9.0 (TID 24) INFO Executor: Running task 3.0 in stage 9.0 (TID 24)
23/01/20 15:42:49.791 Executor task launch worker for task 1.0 in stage 9.0 (TID 22) INFO Executor: Running task 1.0 in stage 9.0 (TID 22)
23/01/20 15:42:49.806 Executor task launch worker for task 1.0 in stage 9.0 (TID 22) INFO Executor: Finished task 1.0 in stage 9.0 (TID 22). 1382 bytes result sent to driver
23/01/20 15:42:49.806 Executor task launch worker for task 0.0 in stage 9.0 (TID 21) INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1382 bytes result sent to driver
23/01/20 15:42:49.806 Executor task launch worker for task 2.0 in stage 9.0 (TID 23) INFO Executor: Finished task 2.0 in stage 9.0 (TID 23). 1382 bytes result sent to driver
23/01/20 15:42:49.806 Executor task launch worker for task 3.0 in stage 9.0 (TID 24) INFO Executor: Finished task 3.0 in stage 9.0 (TID 24). 1382 bytes result sent to driver
23/01/20 15:42:49.806 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 23) in 15 ms on 127.0.0.1 (executor driver) (1/4)
23/01/20 15:42:49.806 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 24) in 15 ms on 127.0.0.1 (executor driver) (2/4)
23/01/20 15:42:49.806 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 15 ms on 127.0.0.1 (executor driver) (3/4)
23/01/20 15:42:49.806 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 22) in 15 ms on 127.0.0.1 (executor driver) (4/4)
23/01/20 15:42:49.806 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/01/20 15:42:49.806 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.015 s
23/01/20 15:42:49.806 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:42:49.806 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/01/20 15:42:49.806 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.018597 s
23/01/20 15:42:50.052 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:65372 in memory (size: 11.8 KiB, free: 838.5 MiB)
23/01/20 15:42:50.055 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:65372 in memory (size: 3.7 KiB, free: 838.5 MiB)
23/01/20 15:42:50.135 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:42:50.135 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:42:50.135 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:26)
23/01/20 15:42:50.135 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:42:50.136 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:42:50.136 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[58] at collect at utils.scala:26), which has no missing parents
23/01/20 15:42:50.138 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.0 KiB, free 586.0 MiB)
23/01/20 15:42:50.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 586.0 MiB)
23/01/20 15:42:50.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 838.5 MiB)
23/01/20 15:42:50.139 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
23/01/20 15:42:50.139 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:42:50.139 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/01/20 15:42:50.140 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:42:50.141 Executor task launch worker for task 0.0 in stage 10.0 (TID 25) INFO Executor: Running task 0.0 in stage 10.0 (TID 25)
23/01/20 15:42:50.143 Executor task launch worker for task 0.0 in stage 10.0 (TID 25) INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 1275 bytes result sent to driver
23/01/20 15:42:50.144 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:42:50.144 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/01/20 15:42:50.144 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collect at utils.scala:26) finished in 0.007 s
23/01/20 15:42:50.144 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:42:50.144 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/01/20 15:42:50.144 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.010331 s
23/01/20 15:42:50.226 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:42:50.227 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:42:50.227 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
23/01/20 15:42:50.227 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:42:50.227 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:42:50.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[60] at collect at utils.scala:26), which has no missing parents
23/01/20 15:42:50.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.0 KiB, free 586.0 MiB)
23/01/20 15:42:50.231 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 585.9 MiB)
23/01/20 15:42:50.231 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 838.5 MiB)
23/01/20 15:42:50.232 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
23/01/20 15:42:50.232 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[60] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:42:50.232 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
23/01/20 15:42:50.233 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 26) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:42:50.234 Executor task launch worker for task 0.0 in stage 11.0 (TID 26) INFO Executor: Running task 0.0 in stage 11.0 (TID 26)
23/01/20 15:42:50.235 Executor task launch worker for task 0.0 in stage 11.0 (TID 26) INFO Executor: Finished task 0.0 in stage 11.0 (TID 26). 1275 bytes result sent to driver
23/01/20 15:42:50.236 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 26) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:42:50.236 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/01/20 15:42:50.236 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0.007 s
23/01/20 15:42:50.236 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:42:50.236 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
23/01/20 15:42:50.236 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.010237 s
23/01/20 15:42:51.666 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 126.3 MiB, free 459.7 MiB)
23/01/20 15:42:51.762 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 455.7 MiB)
23/01/20 15:42:51.763 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 834.5 MiB)
23/01/20 15:42:51.765 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 451.7 MiB)
23/01/20 15:42:51.766 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece1 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 830.5 MiB)
23/01/20 15:42:51.767 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 447.7 MiB)
23/01/20 15:42:51.768 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece2 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 826.5 MiB)
23/01/20 15:42:51.769 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 443.7 MiB)
23/01/20 15:42:51.770 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece3 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 822.5 MiB)
23/01/20 15:42:51.771 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece4 stored as bytes in memory (estimated size 3.9 MiB, free 439.8 MiB)
23/01/20 15:42:51.773 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece4 in memory on 127.0.0.1:65372 (size: 3.9 MiB, free: 818.6 MiB)
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from broadcast at workerhelper.scala:104
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 40.0 B, free 439.8 MiB)
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 69.0 B, free 439.8 MiB)
23/01/20 15:42:51.773 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:65372 (size: 69.0 B, free: 818.6 MiB)
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 23 from broadcast at workerhelper.scala:105
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 248.0 B, free 439.8 MiB)
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 219.0 B, free 439.8 MiB)
23/01/20 15:42:51.773 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:65372 (size: 219.0 B, free: 818.6 MiB)
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at workerhelper.scala:106
23/01/20 15:42:51.773 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1320.0 B, free 439.8 MiB)
23/01/20 15:42:51.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 501.0 B, free 439.8 MiB)
23/01/20 15:42:51.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:65372 (size: 501.0 B, free: 818.6 MiB)
23/01/20 15:42:51.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 818.6 MiB)
23/01/20 15:42:51.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at workerhelper.scala:107
23/01/20 15:42:51.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1928.0 B, free 439.8 MiB)
23/01/20 15:42:51.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1033.0 B, free 439.8 MiB)
23/01/20 15:42:51.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:65372 (size: 1033.0 B, free: 818.6 MiB)
23/01/20 15:42:51.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 818.6 MiB)
23/01/20 15:42:51.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 26 from broadcast at workerhelper.scala:108
23/01/20 15:42:51.866 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 7.0 KiB, free 439.8 MiB)
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 439.8 MiB)
23/01/20 15:42:51.866 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 818.6 MiB)
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/01/20 15:42:51.866 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:42:51.866 Executor task launch worker for task 0.0 in stage 12.0 (TID 27) INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
23/01/20 15:42:51.866 Executor task launch worker for task 0.0 in stage 12.0 (TID 27) INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1275 bytes result sent to driver
23/01/20 15:42:51.866 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:42:51.866 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.000 s
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:42:51.866 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/01/20 15:42:51.866 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0.010539 s
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 78 (sql at <unknown>:0) as input to shuffle 2
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 14 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 13 (sql at <unknown>:0)
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:42:51.945 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[78] at sql at <unknown>:0), which has no missing parents
23/01/20 15:42:51.960 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 29.8 KiB, free 439.8 MiB)
23/01/20 15:42:51.960 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 439.7 MiB)
23/01/20 15:42:51.960 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:65372 (size: 11.8 KiB, free: 818.6 MiB)
23/01/20 15:42:51.960 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
23/01/20 15:42:51.960 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[78] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:42:51.960 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 8 tasks resource profile 0
23/01/20 15:42:51.960 dispatcher-event-loop-3 WARN TaskSetManager: Stage 13 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:42:51.960 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:42:51.960 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:42:51.960 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:42:51.960 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:42:51.976 Executor task launch worker for task 0.0 in stage 13.0 (TID 28) INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
23/01/20 15:42:51.976 Executor task launch worker for task 1.0 in stage 13.0 (TID 29) INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
23/01/20 15:42:51.976 Executor task launch worker for task 3.0 in stage 13.0 (TID 31) INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
23/01/20 15:42:51.976 Executor task launch worker for task 2.0 in stage 13.0 (TID 30) INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
23/01/20 15:42:51.992 Executor task launch worker for task 1.0 in stage 13.0 (TID 29) INFO MemoryStore: Block rdd_65_1 stored as values in memory (estimated size 2.8 MiB, free 434.1 MiB)
23/01/20 15:42:51.992 Executor task launch worker for task 2.0 in stage 13.0 (TID 30) INFO MemoryStore: Block rdd_65_2 stored as values in memory (estimated size 2.8 MiB, free 434.1 MiB)
23/01/20 15:42:51.992 Executor task launch worker for task 0.0 in stage 13.0 (TID 28) INFO MemoryStore: Block rdd_65_0 stored as values in memory (estimated size 2.8 MiB, free 431.3 MiB)
23/01/20 15:42:51.992 Executor task launch worker for task 3.0 in stage 13.0 (TID 31) INFO MemoryStore: Block rdd_65_3 stored as values in memory (estimated size 2.8 MiB, free 428.4 MiB)
23/01/20 15:42:51.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_1 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 815.8 MiB)
23/01/20 15:42:51.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_2 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 813.0 MiB)
23/01/20 15:42:51.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_0 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 810.2 MiB)
23/01/20 15:42:51.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_3 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 807.3 MiB)
23/01/20 15:42:52.899 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 807.3 MiB)
23/01/20 15:42:55.997 Executor task launch worker for task 0.0 in stage 13.0 (TID 28) WARN BlockManager: Putting block rdd_73_0 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:42:55.997 Executor task launch worker for task 0.0 in stage 13.0 (TID 28) WARN BlockManager: Block rdd_73_0 could not be removed as it was not found on disk or in memory
23/01/20 15:42:55.997 Executor task launch worker for task 0.0 in stage 13.0 (TID 28) ERROR Executor: Exception in task 0.0 in stage 13.0 (TID 28)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:42:56.007 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 32) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:42:56.008 task-result-getter-1 WARN TaskSetManager: Lost task 0.0 in stage 13.0 (TID 28) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:42:56.008 Executor task launch worker for task 4.0 in stage 13.0 (TID 32) INFO Executor: Running task 4.0 in stage 13.0 (TID 32)
23/01/20 15:42:56.008 task-result-getter-1 ERROR TaskSetManager: Task 0 in stage 13.0 failed 1 times; aborting job
23/01/20 15:42:56.009 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 13
23/01/20 15:42:56.009 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage cancelled
23/01/20 15:42:56.009 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 13 was cancelled
23/01/20 15:42:56.009 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 2.0 in stage 13.0 (TID 30), reason: Stage cancelled
23/01/20 15:42:56.010 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 13 (sql at <unknown>:0) failed in 4.064 s due to Job aborted due to stage failure: Task 0 in stage 13.0 failed 1 times, most recent failure: Lost task 0.0 in stage 13.0 (TID 28) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:42:56.010 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 3.0 in stage 13.0 (TID 31), reason: Stage cancelled
23/01/20 15:42:56.010 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 4.0 in stage 13.0 (TID 32), reason: Stage cancelled
23/01/20 15:42:56.010 dispatcher-event-loop-3 INFO Executor: Executor is trying to kill task 1.0 in stage 13.0 (TID 29), reason: Stage cancelled
23/01/20 15:42:56.010 Executor task launch worker for task 4.0 in stage 13.0 (TID 32) INFO Executor: Executor killed task 4.0 in stage 13.0 (TID 32), reason: Stage cancelled
23/01/20 15:42:56.012 task-result-getter-0 WARN TaskSetManager: Lost task 4.0 in stage 13.0 (TID 32) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:42:56.039 Executor task launch worker for task 3.0 in stage 13.0 (TID 31) WARN BlockManager: Putting block rdd_73_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:42:56.039 Executor task launch worker for task 3.0 in stage 13.0 (TID 31) WARN BlockManager: Block rdd_73_3 could not be removed as it was not found on disk or in memory
23/01/20 15:42:56.039 Executor task launch worker for task 3.0 in stage 13.0 (TID 31) INFO Executor: Executor interrupted and killed task 3.0 in stage 13.0 (TID 31), reason: Stage cancelled
23/01/20 15:42:56.039 task-result-getter-2 WARN TaskSetManager: Lost task 3.0 in stage 13.0 (TID 31) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:42:56.070 Executor task launch worker for task 1.0 in stage 13.0 (TID 29) WARN BlockManager: Putting block rdd_73_1 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:42:56.070 Executor task launch worker for task 1.0 in stage 13.0 (TID 29) WARN BlockManager: Block rdd_73_1 could not be removed as it was not found on disk or in memory
23/01/20 15:42:56.070 Executor task launch worker for task 1.0 in stage 13.0 (TID 29) INFO Executor: Executor interrupted and killed task 1.0 in stage 13.0 (TID 29), reason: Stage cancelled
23/01/20 15:42:56.070 task-result-getter-3 WARN TaskSetManager: Lost task 1.0 in stage 13.0 (TID 29) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:42:56.070 Executor task launch worker for task 2.0 in stage 13.0 (TID 30) WARN BlockManager: Putting block rdd_73_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:42:56.070 Executor task launch worker for task 2.0 in stage 13.0 (TID 30) WARN BlockManager: Block rdd_73_2 could not be removed as it was not found on disk or in memory
23/01/20 15:42:56.070 Executor task launch worker for task 2.0 in stage 13.0 (TID 30) INFO Executor: Executor interrupted and killed task 2.0 in stage 13.0 (TID 30), reason: Stage cancelled
23/01/20 15:42:56.070 task-result-getter-1 WARN TaskSetManager: Lost task 2.0 in stage 13.0 (TID 30) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:42:56.070 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:45:49.964 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:45:49.995 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:45:50.011 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 6 output partitions
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[81] at collect at utils.scala:26), which has no missing parents
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.1 KiB, free 428.4 MiB)
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 428.4 MiB)
23/01/20 15:45:50.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:65372 (size: 3.7 KiB, free: 807.3 MiB)
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 14 (MapPartitionsRDD[81] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
23/01/20 15:45:50.019 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 6 tasks resource profile 0
23/01/20 15:45:50.019 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 33) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.019 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 34) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.019 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 35) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.019 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 36) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.027 Executor task launch worker for task 3.0 in stage 14.0 (TID 36) INFO Executor: Running task 3.0 in stage 14.0 (TID 36)
23/01/20 15:45:50.027 Executor task launch worker for task 2.0 in stage 14.0 (TID 35) INFO Executor: Running task 2.0 in stage 14.0 (TID 35)
23/01/20 15:45:50.027 Executor task launch worker for task 1.0 in stage 14.0 (TID 34) INFO Executor: Running task 1.0 in stage 14.0 (TID 34)
23/01/20 15:45:50.027 Executor task launch worker for task 0.0 in stage 14.0 (TID 33) INFO Executor: Running task 0.0 in stage 14.0 (TID 33)
23/01/20 15:45:50.027 Executor task launch worker for task 3.0 in stage 14.0 (TID 36) INFO Executor: Finished task 3.0 in stage 14.0 (TID 36). 1339 bytes result sent to driver
23/01/20 15:45:50.027 Executor task launch worker for task 0.0 in stage 14.0 (TID 33) INFO Executor: Finished task 0.0 in stage 14.0 (TID 33). 1339 bytes result sent to driver
23/01/20 15:45:50.027 Executor task launch worker for task 2.0 in stage 14.0 (TID 35) INFO Executor: Finished task 2.0 in stage 14.0 (TID 35). 1339 bytes result sent to driver
23/01/20 15:45:50.027 Executor task launch worker for task 1.0 in stage 14.0 (TID 34) INFO Executor: Finished task 1.0 in stage 14.0 (TID 34). 1339 bytes result sent to driver
23/01/20 15:45:50.027 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 37) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.027 Executor task launch worker for task 4.0 in stage 14.0 (TID 37) INFO Executor: Running task 4.0 in stage 14.0 (TID 37)
23/01/20 15:45:50.027 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 36) in 8 ms on 127.0.0.1 (executor driver) (1/6)
23/01/20 15:45:50.027 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 38) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.027 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 33) in 8 ms on 127.0.0.1 (executor driver) (2/6)
23/01/20 15:45:50.027 Executor task launch worker for task 5.0 in stage 14.0 (TID 38) INFO Executor: Running task 5.0 in stage 14.0 (TID 38)
23/01/20 15:45:50.027 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 35) in 8 ms on 127.0.0.1 (executor driver) (3/6)
23/01/20 15:45:50.027 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 34) in 8 ms on 127.0.0.1 (executor driver) (4/6)
23/01/20 15:45:50.027 Executor task launch worker for task 4.0 in stage 14.0 (TID 37) INFO Executor: Finished task 4.0 in stage 14.0 (TID 37). 1339 bytes result sent to driver
23/01/20 15:45:50.027 Executor task launch worker for task 5.0 in stage 14.0 (TID 38) INFO Executor: Finished task 5.0 in stage 14.0 (TID 38). 1296 bytes result sent to driver
23/01/20 15:45:50.027 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 37) in 0 ms on 127.0.0.1 (executor driver) (5/6)
23/01/20 15:45:50.027 task-result-getter-2 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 38) in 0 ms on 127.0.0.1 (executor driver) (6/6)
23/01/20 15:45:50.027 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/01/20 15:45:50.027 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.008 s
23/01/20 15:45:50.027 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:45:50.027 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/01/20 15:45:50.027 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.024415 s
23/01/20 15:45:50.296 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:65372 in memory (size: 11.8 KiB, free: 807.3 MiB)
23/01/20 15:45:50.305 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:65372 in memory (size: 3.7 KiB, free: 807.3 MiB)
23/01/20 15:45:50.368 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:26)
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[84] at collect at utils.scala:26), which has no missing parents
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 7.0 KiB, free 428.5 MiB)
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 428.5 MiB)
23/01/20 15:45:50.368 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 807.3 MiB)
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[84] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/01/20 15:45:50.368 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 39) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.368 Executor task launch worker for task 0.0 in stage 15.0 (TID 39) INFO Executor: Running task 0.0 in stage 15.0 (TID 39)
23/01/20 15:45:50.368 Executor task launch worker for task 0.0 in stage 15.0 (TID 39) INFO Executor: Finished task 0.0 in stage 15.0 (TID 39). 1232 bytes result sent to driver
23/01/20 15:45:50.368 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 39) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:45:50.368 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collect at utils.scala:26) finished in 0.000 s
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:45:50.368 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/01/20 15:45:50.368 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.011021 s
23/01/20 15:45:50.461 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:45:50.461 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:45:50.462 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:26)
23/01/20 15:45:50.462 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:45:50.462 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:45:50.463 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[86] at collect at utils.scala:26), which has no missing parents
23/01/20 15:45:50.464 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.0 KiB, free 428.5 MiB)
23/01/20 15:45:50.465 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 428.5 MiB)
23/01/20 15:45:50.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 807.3 MiB)
23/01/20 15:45:50.466 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513
23/01/20 15:45:50.466 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[86] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:45:50.466 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
23/01/20 15:45:50.467 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 40) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:45:50.468 Executor task launch worker for task 0.0 in stage 16.0 (TID 40) INFO Executor: Running task 0.0 in stage 16.0 (TID 40)
23/01/20 15:45:50.470 Executor task launch worker for task 0.0 in stage 16.0 (TID 40) INFO Executor: Finished task 0.0 in stage 16.0 (TID 40). 1275 bytes result sent to driver
23/01/20 15:45:50.470 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 40) in 3 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:45:50.470 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
23/01/20 15:45:50.471 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collect at utils.scala:26) finished in 0.008 s
23/01/20 15:45:50.471 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:45:50.471 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
23/01/20 15:45:50.471 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0.010405 s
23/01/20 15:45:52.228 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 126.3 MiB, free 302.2 MiB)
23/01/20 15:45:52.320 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 298.2 MiB)
23/01/20 15:45:52.320 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 803.3 MiB)
23/01/20 15:45:52.320 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 294.2 MiB)
23/01/20 15:45:52.320 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece1 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 799.3 MiB)
23/01/20 15:45:52.320 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 290.2 MiB)
23/01/20 15:45:52.320 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece2 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 795.3 MiB)
23/01/20 15:45:52.320 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 286.2 MiB)
23/01/20 15:45:52.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece3 in memory on 127.0.0.1:65372 (size: 4.0 MiB, free: 791.3 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece4 stored as bytes in memory (estimated size 3.9 MiB, free 282.3 MiB)
23/01/20 15:45:52.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece4 in memory on 127.0.0.1:65372 (size: 3.9 MiB, free: 787.4 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 32 from broadcast at workerhelper.scala:104
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 40.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 69.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:65372 (size: 69.0 B, free: 787.4 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 33 from broadcast at workerhelper.scala:105
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 248.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 219.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:65372 (size: 219.0 B, free: 787.4 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 34 from broadcast at workerhelper.scala:106
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 1320.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 501.0 B, free 282.3 MiB)
23/01/20 15:45:52.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:65372 (size: 501.0 B, free: 787.4 MiB)
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 35 from broadcast at workerhelper.scala:107
23/01/20 15:45:52.336 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 1928.0 B, free 282.3 MiB)
23/01/20 15:45:52.383 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1033.0 B, free 282.3 MiB)
23/01/20 15:45:52.383 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:65372 (size: 1033.0 B, free: 787.4 MiB)
23/01/20 15:45:52.383 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 787.4 MiB)
23/01/20 15:45:52.383 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 36 from broadcast at workerhelper.scala:108
23/01/20 15:45:52.383 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 787.4 MiB)
23/01/20 15:45:52.445 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:26)
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[88] at collect at utils.scala:26), which has no missing parents
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KiB, free 282.3 MiB)
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 282.3 MiB)
23/01/20 15:45:52.445 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:65372 (size: 3.6 KiB, free: 787.4 MiB)
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[88] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
23/01/20 15:45:52.445 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 41) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:45:52.445 Executor task launch worker for task 0.0 in stage 17.0 (TID 41) INFO Executor: Running task 0.0 in stage 17.0 (TID 41)
23/01/20 15:45:52.445 Executor task launch worker for task 0.0 in stage 17.0 (TID 41) INFO Executor: Finished task 0.0 in stage 17.0 (TID 41). 1232 bytes result sent to driver
23/01/20 15:45:52.445 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 41) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:45:52.445 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collect at utils.scala:26) finished in 0.000 s
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:45:52.445 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
23/01/20 15:45:52.445 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0.008064 s
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 104 (sql at <unknown>:0) as input to shuffle 3
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 19 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 18 (sql at <unknown>:0)
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[104] at sql at <unknown>:0), which has no missing parents
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 29.8 KiB, free 282.3 MiB)
23/01/20 15:45:52.508 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 282.3 MiB)
23/01/20 15:45:52.524 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:65372 (size: 11.8 KiB, free: 787.4 MiB)
23/01/20 15:45:52.524 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513
23/01/20 15:45:52.524 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[104] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:45:52.524 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 8 tasks resource profile 0
23/01/20 15:45:52.524 dispatcher-event-loop-5 WARN TaskSetManager: Stage 18 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:45:52.524 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 42) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:45:52.524 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 43) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:45:52.524 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 44) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:45:52.524 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 45) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:45:52.524 Executor task launch worker for task 0.0 in stage 18.0 (TID 42) INFO Executor: Running task 0.0 in stage 18.0 (TID 42)
23/01/20 15:45:52.524 Executor task launch worker for task 1.0 in stage 18.0 (TID 43) INFO Executor: Running task 1.0 in stage 18.0 (TID 43)
23/01/20 15:45:52.524 Executor task launch worker for task 3.0 in stage 18.0 (TID 45) INFO Executor: Running task 3.0 in stage 18.0 (TID 45)
23/01/20 15:45:52.524 Executor task launch worker for task 2.0 in stage 18.0 (TID 44) INFO Executor: Running task 2.0 in stage 18.0 (TID 44)
23/01/20 15:45:52.540 Executor task launch worker for task 1.0 in stage 18.0 (TID 43) INFO MemoryStore: Block rdd_91_1 stored as values in memory (estimated size 2.8 MiB, free 276.6 MiB)
23/01/20 15:45:52.540 Executor task launch worker for task 2.0 in stage 18.0 (TID 44) INFO MemoryStore: Block rdd_91_2 stored as values in memory (estimated size 2.8 MiB, free 276.6 MiB)
23/01/20 15:45:52.540 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_91_1 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 784.6 MiB)
23/01/20 15:45:52.540 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_91_2 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 781.8 MiB)
23/01/20 15:45:52.540 Executor task launch worker for task 0.0 in stage 18.0 (TID 42) INFO MemoryStore: Block rdd_91_0 stored as values in memory (estimated size 2.8 MiB, free 271.0 MiB)
23/01/20 15:45:52.540 Executor task launch worker for task 3.0 in stage 18.0 (TID 45) INFO MemoryStore: Block rdd_91_3 stored as values in memory (estimated size 2.8 MiB, free 271.0 MiB)
23/01/20 15:45:52.540 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_91_3 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 779.0 MiB)
23/01/20 15:45:52.540 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_91_0 in memory on 127.0.0.1:65372 (size: 2.8 MiB, free: 776.1 MiB)
23/01/20 15:45:53.469 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:65372 in memory (size: 3.6 KiB, free: 776.1 MiB)
23/01/20 15:45:57.081 Executor task launch worker for task 0.0 in stage 18.0 (TID 42) WARN BlockManager: Putting block rdd_99_0 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:45:57.081 Executor task launch worker for task 0.0 in stage 18.0 (TID 42) WARN BlockManager: Block rdd_99_0 could not be removed as it was not found on disk or in memory
23/01/20 15:45:57.082 Executor task launch worker for task 0.0 in stage 18.0 (TID 42) ERROR Executor: Exception in task 0.0 in stage 18.0 (TID 42)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:45:57.089 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 46) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:45:57.089 task-result-getter-2 WARN TaskSetManager: Lost task 0.0 in stage 18.0 (TID 42) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:45:57.089 Executor task launch worker for task 4.0 in stage 18.0 (TID 46) INFO Executor: Running task 4.0 in stage 18.0 (TID 46)
23/01/20 15:45:57.089 task-result-getter-2 ERROR TaskSetManager: Task 0 in stage 18.0 failed 1 times; aborting job
23/01/20 15:45:57.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 18
23/01/20 15:45:57.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage cancelled
23/01/20 15:45:57.089 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 3.0 in stage 18.0 (TID 45), reason: Stage cancelled
23/01/20 15:45:57.089 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 4.0 in stage 18.0 (TID 46), reason: Stage cancelled
23/01/20 15:45:57.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 18 was cancelled
23/01/20 15:45:57.089 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 1.0 in stage 18.0 (TID 43), reason: Stage cancelled
23/01/20 15:45:57.089 dispatcher-event-loop-7 INFO Executor: Executor is trying to kill task 2.0 in stage 18.0 (TID 44), reason: Stage cancelled
23/01/20 15:45:57.089 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 18 (sql at <unknown>:0) failed in 4.581 s due to Job aborted due to stage failure: Task 0 in stage 18.0 failed 1 times, most recent failure: Lost task 0.0 in stage 18.0 (TID 42) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:45:57.089 Executor task launch worker for task 4.0 in stage 18.0 (TID 46) INFO Executor: Executor killed task 4.0 in stage 18.0 (TID 46), reason: Stage cancelled
23/01/20 15:45:57.104 task-result-getter-3 WARN TaskSetManager: Lost task 4.0 in stage 18.0 (TID 46) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:45:57.169 Executor task launch worker for task 3.0 in stage 18.0 (TID 45) WARN BlockManager: Putting block rdd_99_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:45:57.169 Executor task launch worker for task 3.0 in stage 18.0 (TID 45) WARN BlockManager: Block rdd_99_3 could not be removed as it was not found on disk or in memory
23/01/20 15:45:57.169 Executor task launch worker for task 3.0 in stage 18.0 (TID 45) INFO Executor: Executor interrupted and killed task 3.0 in stage 18.0 (TID 45), reason: Stage cancelled
23/01/20 15:45:57.169 task-result-getter-1 WARN TaskSetManager: Lost task 3.0 in stage 18.0 (TID 45) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:49:25.437 Thread-1 INFO SparkContext: Invoking stop() from shutdown hook
23/01/20 15:49:25.453 Thread-1 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/01/20 15:49:25.468 dispatcher-event-loop-7 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/20 15:49:25.516 Thread-1 INFO MemoryStore: MemoryStore cleared
23/01/20 15:49:25.516 Thread-1 INFO BlockManager: BlockManager stopped
23/01/20 15:49:25.516 Thread-1 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/20 15:49:25.531 dispatcher-event-loop-5 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/20 15:49:25.534 Thread-1 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618\sparkworker_984.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2140)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:49:25.534 Thread-1 INFO SparkContext: Successfully stopped SparkContext
23/01/20 15:49:25.534 Thread-1 INFO ShutdownHookManager: Shutdown hook called
23/01/20 15:49:25.534 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\Temp\spark-fb816652-d9a3-408d-ab37-b3c4e1e1bbed
23/01/20 15:49:25.534 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b
23/01/20 15:49:25.547 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618\sparkworker_984.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:49:25.547 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618
23/01/20 15:49:25.547 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-8ff4990a-904d-4df6-90e1-cbc22629588b\userFiles-95320a9e-480b-4af5-b806-7bc72a495618\sparkworker_984.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:50:53.814 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:50:53.952 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.1
23/01/20 15:50:53.999 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/20 15:50:54.072 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/01/20 15:50:54.087 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:50:54.087 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/01/20 15:50:54.087 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:50:54.087 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/01/20 15:50:54.119 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/01/20 15:50:54.130 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/01/20 15:50:54.130 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/01/20 15:50:54.184 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: anthonyp
23/01/20 15:50:54.184 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: anthonyp
23/01/20 15:50:54.184 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/01/20 15:50:54.184 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/01/20 15:50:54.184 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(anthonyp); groups with view permissions: Set(); users  with modify permissions: Set(anthonyp); groups with modify permissions: Set()
23/01/20 15:50:54.315 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51124.
23/01/20 15:50:54.344 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/01/20 15:50:54.376 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/01/20 15:50:54.397 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/20 15:50:54.397 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/20 15:50:54.401 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/01/20 15:50:54.420 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\blockmgr-febac789-143f-4dc2-9a5f-3e2d01d44017
23/01/20 15:50:54.434 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
23/01/20 15:50:54.438 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/20 15:50:54.438 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local]. Please check your configured local directories.
23/01/20 15:50:54.655 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/20 15:50:54.688 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/anthonyp/AppData/Local/R/win-library/4.2/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:51124/jars/sparklyr-master-2.12.jar with timestamp 1674258653936
23/01/20 15:50:54.760 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/01/20 15:50:54.766 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/01/20 15:50:54.775 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:51124/jars/sparklyr-master-2.12.jar with timestamp 1674258653936
23/01/20 15:50:54.804 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51124 after 14 ms (0 ms spent in bootstraps)
23/01/20 15:50:54.804 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:51124/jars/sparklyr-master-2.12.jar to C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f\fetchFileTemp5986070878734806778.tmp
23/01/20 15:50:54.898 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local/spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4/userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f/sparklyr-master-2.12.jar to class loader
23/01/20 15:50:54.913 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51172.
23/01/20 15:50:54.913 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:51172
23/01/20 15:50:54.913 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/20 15:50:54.929 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51172, None)
23/01/20 15:50:54.929 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51172 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 51172, None)
23/01/20 15:50:54.929 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51172, None)
23/01/20 15:50:54.929 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51172, None)
23/01/20 15:50:55.224 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive') to the value of spark.sql.warehouse.dir.
23/01/20 15:50:55.230 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive'.
23/01/20 15:50:57.880 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/01/20 15:50:57.992 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:50:58.288 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive
23/01/20 15:50:58.500 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 15:50:58.501 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 15:50:58.501 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 15:50:58.540 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/01/20 15:50:58.636 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/01/20 15:50:58.636 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/01/20 15:50:59.437 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/01/20 15:51:00.494 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 15:51:00.496 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/01/20 15:51:00.541 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/01/20 15:51:00.542 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.229
23/01/20 15:51:00.553 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/01/20 15:51:00.671 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/01/20 15:51:00.671 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/01/20 15:51:00.702 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/01/20 15:51:00.782 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:00.784 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:00.797 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/01/20 15:51:00.797 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/01/20 15:51:00.798 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/01/20 15:51:00.799 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:00.799 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:00.800 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:00.800 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:00.802 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:51:00.802 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:51:01.062 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:01.063 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:01.065 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:01.065 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:01.066 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:51:01.066 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:51:30.425 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:51:30.832 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 107.913 ms
23/01/20 15:51:30.945 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:51:30.951 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.004688 s
23/01/20 15:51:31.466 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.5772 ms
23/01/20 15:51:31.466 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:51:31.482 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:51:31.482 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/01/20 15:51:31.482 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:51:31.482 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:51:31.482 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/01/20 15:51:31.529 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:51:31.576 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:51:31.576 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:51:31.576 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
23/01/20 15:51:31.592 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:51:31.592 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/01/20 15:51:31.636 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:51:31.658 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/01/20 15:51:31.854 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
23/01/20 15:51:31.861 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 231 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:51:31.861 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/01/20 15:51:31.861 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.363 s
23/01/20 15:51:31.861 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:51:31.861 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/01/20 15:51:31.861 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.392270 s
23/01/20 15:51:31.893 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.4693 ms
23/01/20 15:51:32.002 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:51:32.002 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:51:32.002 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/01/20 15:51:32.002 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:51:32.002 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:51:32.002 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:51:32.018 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/01/20 15:51:32.018 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:51:32.018 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/01/20 15:51:32.018 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1275 bytes result sent to driver
23/01/20 15:51:32.018 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:51:32.018 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.016 s
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:51:32.018 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/01/20 15:51:32.018 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.015520 s
23/01/20 15:51:34.651 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:51:34.656 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:51:34.671 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 125.7 MiB, free 786.6 MiB)
23/01/20 15:51:34.789 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 782.6 MiB)
23/01/20 15:51:34.790 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 908.3 MiB)
23/01/20 15:51:34.792 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 778.6 MiB)
23/01/20 15:51:34.800 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece1 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 904.3 MiB)
23/01/20 15:51:34.802 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 774.6 MiB)
23/01/20 15:51:34.802 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece2 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 900.3 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 770.6 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece3 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 896.3 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece4 stored as bytes in memory (estimated size 3.7 MiB, free 766.9 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece4 in memory on 127.0.0.1:51172 (size: 3.7 MiB, free: 892.6 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 2 from broadcast at workerhelper.scala:104
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 40.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 69.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51172 (size: 69.0 B, free: 892.6 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 3 from broadcast at workerhelper.scala:105
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 248.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 219.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51172 (size: 219.0 B, free: 892.6 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 4 from broadcast at workerhelper.scala:106
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1320.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 501.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51172 (size: 501.0 B, free: 892.6 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 5 from broadcast at workerhelper.scala:107
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1928.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1033.0 B, free 766.9 MiB)
23/01/20 15:51:34.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51172 (size: 1033.0 B, free: 892.6 MiB)
23/01/20 15:51:34.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 6 from broadcast at workerhelper.scala:108
23/01/20 15:51:34.883 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:51:34.883 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KiB, free 766.9 MiB)
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 766.9 MiB)
23/01/20 15:51:34.899 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 892.6 MiB)
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/01/20 15:51:34.899 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:51:34.899 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/01/20 15:51:34.899 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1318 bytes result sent to driver
23/01/20 15:51:34.899 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:51:34.899 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.000 s
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:51:34.899 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/01/20 15:51:34.899 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.015442 s
23/01/20 15:51:35.103 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.6699 ms
23/01/20 15:51:35.134 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 25.1632 ms
23/01/20 15:51:35.149 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.4225 ms
23/01/20 15:51:35.197 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 26 (sql at <unknown>:0) as input to shuffle 0
23/01/20 15:51:35.212 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:51:35.212 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (sql at <unknown>:0)
23/01/20 15:51:35.212 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:51:35.212 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:51:35.212 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0), which has no missing parents
23/01/20 15:51:35.244 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.8 KiB, free 766.9 MiB)
23/01/20 15:51:35.244 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 766.8 MiB)
23/01/20 15:51:35.244 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51172 (size: 11.8 KiB, free: 892.5 MiB)
23/01/20 15:51:35.244 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
23/01/20 15:51:35.244 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:51:35.244 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
23/01/20 15:51:35.263 dispatcher-event-loop-6 WARN TaskSetManager: Stage 3 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:51:35.263 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.322 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.322 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 892.5 MiB)
23/01/20 15:51:35.322 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.322 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.339 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.342 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 3009944 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.344 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9) (127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 2977439 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.347 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10) (127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 3013382 bytes) taskResourceAssignments Map()
23/01/20 15:51:35.347 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/01/20 15:51:35.348 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
23/01/20 15:51:35.348 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
23/01/20 15:51:35.349 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO Executor: Running task 7.0 in stage 3.0 (TID 10)
23/01/20 15:51:35.349 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
23/01/20 15:51:35.349 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
23/01/20 15:51:35.350 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO Executor: Running task 5.0 in stage 3.0 (TID 8)
23/01/20 15:51:35.353 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO Executor: Running task 6.0 in stage 3.0 (TID 9)
23/01/20 15:51:35.450 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 2.8 MiB, free 764.0 MiB)
23/01/20 15:51:35.450 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_4 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 889.7 MiB)
23/01/20 15:51:35.450 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO MemoryStore: Block rdd_13_5 stored as values in memory (estimated size 2.8 MiB, free 761.2 MiB)
23/01/20 15:51:35.463 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO MemoryStore: Block rdd_13_7 stored as values in memory (estimated size 2.8 MiB, free 758.3 MiB)
23/01/20 15:51:35.463 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 2.8 MiB, free 755.5 MiB)
23/01/20 15:51:35.466 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 2.8 MiB, free 752.7 MiB)
23/01/20 15:51:35.466 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 2.8 MiB, free 749.9 MiB)
23/01/20 15:51:35.466 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO MemoryStore: Block rdd_13_6 stored as values in memory (estimated size 2.8 MiB, free 747.1 MiB)
23/01/20 15:51:35.466 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 2.8 MiB, free 744.2 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_5 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 886.9 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_6 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 884.0 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 881.2 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 878.4 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 875.6 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_7 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 872.7 MiB)
23/01/20 15:51:35.466 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 869.9 MiB)
23/01/20 15:51:35.466 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO CodeGenerator: Code generated in 4.2651 ms
23/01/20 15:51:35.498 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO CodeGenerator: Code generated in 20.1017 ms
23/01/20 15:51:35.513 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 6.6217 ms
23/01/20 15:51:43.230 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Putting block rdd_21_4 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) WARN BlockManager: Putting block rdd_21_1 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) WARN BlockManager: Putting block rdd_21_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Putting block rdd_21_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Putting block rdd_21_5 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Putting block rdd_21_7 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) WARN BlockManager: Putting block rdd_21_6 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:51:43.230 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Block rdd_21_5 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Block rdd_21_4 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) WARN BlockManager: Block rdd_21_2 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Block rdd_21_3 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) WARN BlockManager: Block rdd_21_1 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Block rdd_21_7 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) WARN BlockManager: Block rdd_21_6 could not be removed as it was not found on disk or in memory
23/01/20 15:51:43.230 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) ERROR Executor: Exception in task 6.0 in stage 3.0 (TID 9)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) ERROR Executor: Exception in task 2.0 in stage 3.0 (TID 5)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) ERROR Executor: Exception in task 5.0 in stage 3.0 (TID 8)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) ERROR Executor: Exception in task 1.0 in stage 3.0 (TID 4)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) ERROR Executor: Exception in task 7.0 in stage 3.0 (TID 10)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 7)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.230 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) ERROR Executor: Exception in task 3.0 in stage 3.0 (TID 6)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:51:43.261 task-result-getter-0 WARN TaskSetManager: Lost task 7.0 in stage 3.0 (TID 10) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:51:43.261 task-result-getter-0 ERROR TaskSetManager: Task 7 in stage 3.0 failed 1 times; aborting job
23/01/20 15:51:43.261 task-result-getter-2 INFO TaskSetManager: Lost task 2.0 in stage 3.0 (TID 5) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 1]
23/01/20 15:51:43.261 task-result-getter-1 INFO TaskSetManager: Lost task 4.0 in stage 3.0 (TID 7) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 2]
23/01/20 15:51:43.261 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 3
23/01/20 15:51:43.261 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage cancelled
23/01/20 15:51:43.273 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 3 was cancelled
23/01/20 15:51:43.274 task-result-getter-3 INFO TaskSetManager: Lost task 5.0 in stage 3.0 (TID 8) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 3]
23/01/20 15:51:43.274 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) failed in 8.061 s due to Job aborted due to stage failure: Task 7 in stage 3.0 failed 1 times, most recent failure: Lost task 7.0 in stage 3.0 (TID 10) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:51:43.274 task-result-getter-2 INFO TaskSetManager: Lost task 3.0 in stage 3.0 (TID 6) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 4]
23/01/20 15:51:43.274 task-result-getter-0 INFO TaskSetManager: Lost task 6.0 in stage 3.0 (TID 9) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 5]
23/01/20 15:51:43.275 task-result-getter-1 INFO TaskSetManager: Lost task 1.0 in stage 3.0 (TID 4) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 6]
23/01/20 15:51:43.275 dispatcher-event-loop-6 INFO Executor: Executor is trying to kill task 0.0 in stage 3.0 (TID 3), reason: Stage cancelled
23/01/20 15:51:52.779 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:52.779 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:52.781 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:51:52.781 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:51:52.782 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:51:52.782 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:51:52.821 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.618 ms
23/01/20 15:51:52.847 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.553 ms
23/01/20 15:51:52.859 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.118 ms
23/01/20 15:55:43.779 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:55:43.779 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:55:43.781 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:55:43.781 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:55:43.782 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:55:43.783 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:55:43.843 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:55:43.843 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:55:43.845 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:55:43.845 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:55:43.847 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:55:43.847 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:56:00.151 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:56:00.206 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 2 output partitions
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[29] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.1 KiB, free 744.2 MiB)
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 744.2 MiB)
23/01/20 15:56:00.206 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51172 (size: 3.7 KiB, free: 869.9 MiB)
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[29] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
23/01/20 15:56:00.206 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0
23/01/20 15:56:00.221 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:00.221 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 12) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:00.221 Executor task launch worker for task 0.0 in stage 4.0 (TID 11) INFO Executor: Running task 0.0 in stage 4.0 (TID 11)
23/01/20 15:56:00.221 Executor task launch worker for task 1.0 in stage 4.0 (TID 12) INFO Executor: Running task 1.0 in stage 4.0 (TID 12)
23/01/20 15:56:00.221 Executor task launch worker for task 1.0 in stage 4.0 (TID 12) INFO Executor: Finished task 1.0 in stage 4.0 (TID 12). 1382 bytes result sent to driver
23/01/20 15:56:00.221 Executor task launch worker for task 0.0 in stage 4.0 (TID 11) INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 1382 bytes result sent to driver
23/01/20 15:56:00.221 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 12) in 0 ms on 127.0.0.1 (executor driver) (1/2)
23/01/20 15:56:00.221 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 0 ms on 127.0.0.1 (executor driver) (2/2)
23/01/20 15:56:00.221 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/01/20 15:56:00.221 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.015 s
23/01/20 15:56:00.221 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:00.221 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/01/20 15:56:00.221 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.026317 s
23/01/20 15:56:00.237 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.7044 ms
23/01/20 15:56:00.479 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:00.480 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:00.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
23/01/20 15:56:00.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:00.480 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:00.481 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:00.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KiB, free 744.2 MiB)
23/01/20 15:56:00.485 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 744.2 MiB)
23/01/20 15:56:00.486 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 869.9 MiB)
23/01/20 15:56:00.487 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:00.487 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:00.487 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/01/20 15:56:00.488 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 13) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:00.489 Executor task launch worker for task 0.0 in stage 5.0 (TID 13) INFO Executor: Running task 0.0 in stage 5.0 (TID 13)
23/01/20 15:56:00.492 Executor task launch worker for task 0.0 in stage 5.0 (TID 13) INFO Executor: Finished task 0.0 in stage 5.0 (TID 13). 1318 bytes result sent to driver
23/01/20 15:56:00.493 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 13) in 6 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:00.493 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/01/20 15:56:00.493 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.011 s
23/01/20 15:56:00.493 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:00.493 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/01/20 15:56:00.494 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.014977 s
23/01/20 15:56:00.580 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:00.581 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:00.581 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
23/01/20 15:56:00.581 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:00.581 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:00.582 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:00.584 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KiB, free 744.2 MiB)
23/01/20 15:56:00.586 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 744.2 MiB)
23/01/20 15:56:00.587 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 869.9 MiB)
23/01/20 15:56:00.587 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:00.588 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:00.588 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/01/20 15:56:00.589 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 14) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:00.590 Executor task launch worker for task 0.0 in stage 6.0 (TID 14) INFO Executor: Running task 0.0 in stage 6.0 (TID 14)
23/01/20 15:56:00.593 Executor task launch worker for task 0.0 in stage 6.0 (TID 14) INFO Executor: Finished task 0.0 in stage 6.0 (TID 14). 1318 bytes result sent to driver
23/01/20 15:56:00.593 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 14) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:00.594 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/01/20 15:56:00.594 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0.011 s
23/01/20 15:56:00.594 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:00.594 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/01/20 15:56:00.594 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0.014271 s
23/01/20 15:56:02.644 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51172 in memory (size: 3.7 KiB, free: 869.9 MiB)
23/01/20 15:56:02.645 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 869.9 MiB)
23/01/20 15:56:02.645 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 869.9 MiB)
23/01/20 15:56:02.684 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 125.7 MiB, free 618.6 MiB)
23/01/20 15:56:02.791 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 614.6 MiB)
23/01/20 15:56:02.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 865.9 MiB)
23/01/20 15:56:02.794 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 610.6 MiB)
23/01/20 15:56:02.795 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece1 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 861.9 MiB)
23/01/20 15:56:02.797 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 606.6 MiB)
23/01/20 15:56:02.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece2 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 857.9 MiB)
23/01/20 15:56:02.798 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 602.6 MiB)
23/01/20 15:56:02.800 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece3 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 853.9 MiB)
23/01/20 15:56:02.800 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece4 stored as bytes in memory (estimated size 3.7 MiB, free 598.8 MiB)
23/01/20 15:56:02.801 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece4 in memory on 127.0.0.1:51172 (size: 3.7 MiB, free: 850.2 MiB)
23/01/20 15:56:02.802 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at workerhelper.scala:104
23/01/20 15:56:02.803 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 40.0 B, free 598.8 MiB)
23/01/20 15:56:02.804 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 69.0 B, free 598.8 MiB)
23/01/20 15:56:02.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51172 (size: 69.0 B, free: 850.2 MiB)
23/01/20 15:56:02.806 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from broadcast at workerhelper.scala:105
23/01/20 15:56:02.806 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 248.0 B, free 598.8 MiB)
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 219.0 B, free 598.8 MiB)
23/01/20 15:56:02.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51172 (size: 219.0 B, free: 850.2 MiB)
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 14 from broadcast at workerhelper.scala:106
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1320.0 B, free 598.8 MiB)
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 501.0 B, free 598.8 MiB)
23/01/20 15:56:02.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51172 (size: 501.0 B, free: 850.2 MiB)
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from broadcast at workerhelper.scala:107
23/01/20 15:56:02.836 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 1928.0 B, free 598.8 MiB)
23/01/20 15:56:02.851 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1033.0 B, free 598.8 MiB)
23/01/20 15:56:02.851 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51172 (size: 1033.0 B, free: 850.2 MiB)
23/01/20 15:56:02.851 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 16 from broadcast at workerhelper.scala:108
23/01/20 15:56:02.901 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[36] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KiB, free 598.8 MiB)
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 598.8 MiB)
23/01/20 15:56:02.901 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 850.2 MiB)
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[36] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:02.901 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/01/20 15:56:02.901 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 15) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:02.901 Executor task launch worker for task 0.0 in stage 7.0 (TID 15) INFO Executor: Running task 0.0 in stage 7.0 (TID 15)
23/01/20 15:56:02.917 Executor task launch worker for task 0.0 in stage 7.0 (TID 15) INFO Executor: Finished task 0.0 in stage 7.0 (TID 15). 1275 bytes result sent to driver
23/01/20 15:56:02.917 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 15) in 16 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:02.917 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/01/20 15:56:02.917 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.016 s
23/01/20 15:56:02.917 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:02.917 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/01/20 15:56:02.917 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.009706 s
23/01/20 15:56:02.985 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 52 (sql at <unknown>:0) as input to shuffle 1
23/01/20 15:56:02.986 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 9 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:56:02.986 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 8 (sql at <unknown>:0)
23/01/20 15:56:02.986 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:02.987 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:02.988 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[52] at sql at <unknown>:0), which has no missing parents
23/01/20 15:56:03.004 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 29.8 KiB, free 598.8 MiB)
23/01/20 15:56:03.004 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 598.8 MiB)
23/01/20 15:56:03.004 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51172 (size: 11.8 KiB, free: 850.1 MiB)
23/01/20 15:56:03.004 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:03.004 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[52] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:56:03.004 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
23/01/20 15:56:03.004 dispatcher-event-loop-1 WARN TaskSetManager: Stage 8 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:56:03.004 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 16) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.004 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 17) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 18) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 19) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 20) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 21) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 3009944 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 22) (127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 2977439 bytes) taskResourceAssignments Map()
23/01/20 15:56:03.019 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) INFO Executor: Running task 1.0 in stage 8.0 (TID 17)
23/01/20 15:56:03.019 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO Executor: Running task 0.0 in stage 8.0 (TID 16)
23/01/20 15:56:03.019 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) INFO Executor: Running task 2.0 in stage 8.0 (TID 18)
23/01/20 15:56:03.019 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) INFO Executor: Running task 3.0 in stage 8.0 (TID 19)
23/01/20 15:56:03.019 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) INFO Executor: Running task 4.0 in stage 8.0 (TID 20)
23/01/20 15:56:03.019 Executor task launch worker for task 5.0 in stage 8.0 (TID 21) INFO Executor: Running task 5.0 in stage 8.0 (TID 21)
23/01/20 15:56:03.019 Executor task launch worker for task 6.0 in stage 8.0 (TID 22) INFO Executor: Running task 6.0 in stage 8.0 (TID 22)
23/01/20 15:56:03.049 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) INFO MemoryStore: Block rdd_39_2 stored as values in memory (estimated size 2.8 MiB, free 595.9 MiB)
23/01/20 15:56:03.050 Executor task launch worker for task 5.0 in stage 8.0 (TID 21) INFO MemoryStore: Block rdd_39_5 stored as values in memory (estimated size 2.8 MiB, free 593.1 MiB)
23/01/20 15:56:03.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_2 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 847.3 MiB)
23/01/20 15:56:03.051 Executor task launch worker for task 3.0 in stage 8.0 (TID 19) INFO MemoryStore: Block rdd_39_3 stored as values in memory (estimated size 2.8 MiB, free 587.4 MiB)
23/01/20 15:56:03.051 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 2.8 MiB, free 587.4 MiB)
23/01/20 15:56:03.052 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_5 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 844.5 MiB)
23/01/20 15:56:03.052 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_0 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 841.6 MiB)
23/01/20 15:56:03.053 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_3 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 838.8 MiB)
23/01/20 15:56:03.056 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) INFO MemoryStore: Block rdd_39_1 stored as values in memory (estimated size 2.8 MiB, free 584.6 MiB)
23/01/20 15:56:03.056 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_1 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 836.0 MiB)
23/01/20 15:56:03.056 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) INFO MemoryStore: Block rdd_39_4 stored as values in memory (estimated size 2.8 MiB, free 581.8 MiB)
23/01/20 15:56:03.211 Executor task launch worker for task 6.0 in stage 8.0 (TID 22) INFO MemoryStore: Block rdd_39_6 stored as values in memory (estimated size 2.8 MiB, free 579.0 MiB)
23/01/20 15:56:03.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_4 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 833.2 MiB)
23/01/20 15:56:03.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_39_6 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 830.3 MiB)
23/01/20 15:56:03.226 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 830.3 MiB)
23/01/20 15:56:09.228 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) WARN BlockManager: Putting block rdd_47_1 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.228 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) WARN BlockManager: Block rdd_47_1 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.228 Executor task launch worker for task 1.0 in stage 8.0 (TID 17) ERROR Executor: Exception in task 1.0 in stage 8.0 (TID 17)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:56:09.243 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 23) (127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 3013382 bytes) taskResourceAssignments Map()
23/01/20 15:56:09.243 task-result-getter-2 WARN TaskSetManager: Lost task 1.0 in stage 8.0 (TID 17) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:56:09.243 Executor task launch worker for task 7.0 in stage 8.0 (TID 23) INFO Executor: Running task 7.0 in stage 8.0 (TID 23)
23/01/20 15:56:09.243 task-result-getter-2 ERROR TaskSetManager: Task 1 in stage 8.0 failed 1 times; aborting job
23/01/20 15:56:09.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 8
23/01/20 15:56:09.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage cancelled
23/01/20 15:56:09.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 8 was cancelled
23/01/20 15:56:09.243 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 8 (sql at <unknown>:0) failed in 6.254 s due to Job aborted due to stage failure: Task 1 in stage 8.0 failed 1 times, most recent failure: Lost task 1.0 in stage 8.0 (TID 17) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 3.0 in stage 8.0 (TID 19), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 0.0 in stage 8.0 (TID 16), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 4.0 in stage 8.0 (TID 20), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 5.0 in stage 8.0 (TID 21), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 2.0 in stage 8.0 (TID 18), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 6.0 in stage 8.0 (TID 22), reason: Stage cancelled
23/01/20 15:56:09.243 dispatcher-event-loop-5 INFO Executor: Executor is trying to kill task 7.0 in stage 8.0 (TID 23), reason: Stage cancelled
23/01/20 15:56:09.243 Executor task launch worker for task 7.0 in stage 8.0 (TID 23) INFO Executor: Executor killed task 7.0 in stage 8.0 (TID 23), reason: Stage cancelled
23/01/20 15:56:09.259 task-result-getter-0 WARN TaskSetManager: Lost task 7.0 in stage 8.0 (TID 23) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:09.352 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) WARN BlockManager: Putting block rdd_47_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.353 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) WARN BlockManager: Block rdd_47_2 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.355 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) WARN BlockManager: Putting block rdd_47_0 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.355 Executor task launch worker for task 2.0 in stage 8.0 (TID 18) INFO Executor: Executor interrupted and killed task 2.0 in stage 8.0 (TID 18), reason: Stage cancelled
23/01/20 15:56:09.356 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) WARN BlockManager: Block rdd_47_0 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.357 Executor task launch worker for task 0.0 in stage 8.0 (TID 16) INFO Executor: Executor interrupted and killed task 0.0 in stage 8.0 (TID 16), reason: Stage cancelled
23/01/20 15:56:09.358 task-result-getter-1 WARN TaskSetManager: Lost task 2.0 in stage 8.0 (TID 18) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:09.358 task-result-getter-3 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 16) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:09.358 Executor task launch worker for task 5.0 in stage 8.0 (TID 21) WARN BlockManager: Putting block rdd_47_5 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.359 Executor task launch worker for task 5.0 in stage 8.0 (TID 21) WARN BlockManager: Block rdd_47_5 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.360 Executor task launch worker for task 5.0 in stage 8.0 (TID 21) INFO Executor: Executor interrupted and killed task 5.0 in stage 8.0 (TID 21), reason: Stage cancelled
23/01/20 15:56:09.363 task-result-getter-2 WARN TaskSetManager: Lost task 5.0 in stage 8.0 (TID 21) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:09.370 Executor task launch worker for task 6.0 in stage 8.0 (TID 22) WARN BlockManager: Putting block rdd_47_6 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.370 Executor task launch worker for task 6.0 in stage 8.0 (TID 22) WARN BlockManager: Block rdd_47_6 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.370 Executor task launch worker for task 6.0 in stage 8.0 (TID 22) INFO Executor: Executor interrupted and killed task 6.0 in stage 8.0 (TID 22), reason: Stage cancelled
23/01/20 15:56:09.370 task-result-getter-0 WARN TaskSetManager: Lost task 6.0 in stage 8.0 (TID 22) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:09.386 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) WARN BlockManager: Putting block rdd_47_4 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:09.386 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) WARN BlockManager: Block rdd_47_4 could not be removed as it was not found on disk or in memory
23/01/20 15:56:09.386 Executor task launch worker for task 4.0 in stage 8.0 (TID 20) INFO Executor: Executor interrupted and killed task 4.0 in stage 8.0 (TID 20), reason: Stage cancelled
23/01/20 15:56:09.386 task-result-getter-1 WARN TaskSetManager: Lost task 4.0 in stage 8.0 (TID 20) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:56:49.575 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:56:49.622 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:49.622 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 4 output partitions
23/01/20 15:56:49.622 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
23/01/20 15:56:49.622 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:49.622 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:49.622 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[55] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.1 KiB, free 579.0 MiB)
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 579.0 MiB)
23/01/20 15:56:49.638 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51172 (size: 3.7 KiB, free: 830.3 MiB)
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[55] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
23/01/20 15:56:49.638 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 24) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:49.638 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 25) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:49.638 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 26) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:49.638 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 27) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
23/01/20 15:56:49.638 Executor task launch worker for task 0.0 in stage 9.0 (TID 24) INFO Executor: Running task 0.0 in stage 9.0 (TID 24)
23/01/20 15:56:49.638 Executor task launch worker for task 1.0 in stage 9.0 (TID 25) INFO Executor: Running task 1.0 in stage 9.0 (TID 25)
23/01/20 15:56:49.638 Executor task launch worker for task 3.0 in stage 9.0 (TID 27) INFO Executor: Running task 3.0 in stage 9.0 (TID 27)
23/01/20 15:56:49.638 Executor task launch worker for task 2.0 in stage 9.0 (TID 26) INFO Executor: Running task 2.0 in stage 9.0 (TID 26)
23/01/20 15:56:49.638 Executor task launch worker for task 3.0 in stage 9.0 (TID 27) INFO Executor: Finished task 3.0 in stage 9.0 (TID 27). 1339 bytes result sent to driver
23/01/20 15:56:49.638 Executor task launch worker for task 1.0 in stage 9.0 (TID 25) INFO Executor: Finished task 1.0 in stage 9.0 (TID 25). 1339 bytes result sent to driver
23/01/20 15:56:49.638 Executor task launch worker for task 0.0 in stage 9.0 (TID 24) INFO Executor: Finished task 0.0 in stage 9.0 (TID 24). 1339 bytes result sent to driver
23/01/20 15:56:49.638 Executor task launch worker for task 2.0 in stage 9.0 (TID 26) INFO Executor: Finished task 2.0 in stage 9.0 (TID 26). 1339 bytes result sent to driver
23/01/20 15:56:49.638 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 27) in 0 ms on 127.0.0.1 (executor driver) (1/4)
23/01/20 15:56:49.638 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 24) in 0 ms on 127.0.0.1 (executor driver) (2/4)
23/01/20 15:56:49.638 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 25) in 0 ms on 127.0.0.1 (executor driver) (3/4)
23/01/20 15:56:49.638 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 26) in 0 ms on 127.0.0.1 (executor driver) (4/4)
23/01/20 15:56:49.638 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0.016 s
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:49.638 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/01/20 15:56:49.638 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0.016400 s
23/01/20 15:56:49.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:51172 in memory (size: 3.7 KiB, free: 830.3 MiB)
23/01/20 15:56:49.942 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:49.942 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:49.943 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:26)
23/01/20 15:56:49.943 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:49.943 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:49.943 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[58] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:49.946 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.0 KiB, free 579.0 MiB)
23/01/20 15:56:49.946 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 579.0 MiB)
23/01/20 15:56:49.947 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 830.3 MiB)
23/01/20 15:56:49.947 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:49.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:49.948 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/01/20 15:56:49.949 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 28) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:49.949 Executor task launch worker for task 0.0 in stage 10.0 (TID 28) INFO Executor: Running task 0.0 in stage 10.0 (TID 28)
23/01/20 15:56:49.951 Executor task launch worker for task 0.0 in stage 10.0 (TID 28) INFO Executor: Finished task 0.0 in stage 10.0 (TID 28). 1275 bytes result sent to driver
23/01/20 15:56:49.952 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 28) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:49.952 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/01/20 15:56:49.952 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collect at utils.scala:26) finished in 0.008 s
23/01/20 15:56:49.952 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:49.952 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/01/20 15:56:49.953 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0.010608 s
23/01/20 15:56:50.033 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:50.034 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:50.034 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
23/01/20 15:56:50.034 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:50.034 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:50.035 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[60] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:50.037 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.0 KiB, free 579.0 MiB)
23/01/20 15:56:50.038 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 579.0 MiB)
23/01/20 15:56:50.039 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 830.3 MiB)
23/01/20 15:56:50.039 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:50.039 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[60] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:50.040 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
23/01/20 15:56:50.041 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 29) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:50.041 Executor task launch worker for task 0.0 in stage 11.0 (TID 29) INFO Executor: Running task 0.0 in stage 11.0 (TID 29)
23/01/20 15:56:50.044 Executor task launch worker for task 0.0 in stage 11.0 (TID 29) INFO Executor: Finished task 0.0 in stage 11.0 (TID 29). 1275 bytes result sent to driver
23/01/20 15:56:50.044 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 29) in 4 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:50.044 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/01/20 15:56:50.045 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0.009 s
23/01/20 15:56:50.045 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:50.045 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
23/01/20 15:56:50.045 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.011815 s
23/01/20 15:56:51.435 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 125.7 MiB, free 453.3 MiB)
23/01/20 15:56:51.514 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 449.3 MiB)
23/01/20 15:56:51.514 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 826.3 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 445.3 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece1 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 822.3 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 441.3 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece2 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 818.3 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 437.3 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece3 in memory on 127.0.0.1:51172 (size: 4.0 MiB, free: 814.3 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece4 stored as bytes in memory (estimated size 3.7 MiB, free 433.6 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece4 in memory on 127.0.0.1:51172 (size: 3.7 MiB, free: 810.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from broadcast at workerhelper.scala:104
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 40.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 69.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:51172 (size: 69.0 B, free: 810.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 23 from broadcast at workerhelper.scala:105
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 248.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 219.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:51172 (size: 219.0 B, free: 810.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at workerhelper.scala:106
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1320.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 501.0 B, free 433.6 MiB)
23/01/20 15:56:51.530 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:51172 (size: 501.0 B, free: 810.6 MiB)
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at workerhelper.scala:107
23/01/20 15:56:51.530 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1928.0 B, free 433.6 MiB)
23/01/20 15:56:51.545 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1033.0 B, free 433.6 MiB)
23/01/20 15:56:51.545 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:51172 (size: 1033.0 B, free: 810.6 MiB)
23/01/20 15:56:51.545 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 26 from broadcast at workerhelper.scala:108
23/01/20 15:56:51.593 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[62] at collect at utils.scala:26), which has no missing parents
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 7.0 KiB, free 433.5 MiB)
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 433.5 MiB)
23/01/20 15:56:51.593 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:51172 (size: 3.6 KiB, free: 810.6 MiB)
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[62] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:56:51.593 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/01/20 15:56:51.593 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 30) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.593 Executor task launch worker for task 0.0 in stage 12.0 (TID 30) INFO Executor: Running task 0.0 in stage 12.0 (TID 30)
23/01/20 15:56:51.608 Executor task launch worker for task 0.0 in stage 12.0 (TID 30) INFO Executor: Finished task 0.0 in stage 12.0 (TID 30). 1318 bytes result sent to driver
23/01/20 15:56:51.608 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 30) in 15 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:56:51.608 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/01/20 15:56:51.608 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.015 s
23/01/20 15:56:51.608 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:56:51.608 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/01/20 15:56:51.608 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0.010756 s
23/01/20 15:56:51.659 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 78 (sql at <unknown>:0) as input to shuffle 2
23/01/20 15:56:51.659 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 14 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:56:51.659 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 13 (sql at <unknown>:0)
23/01/20 15:56:51.659 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:56:51.671 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:56:51.671 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[78] at sql at <unknown>:0), which has no missing parents
23/01/20 15:56:51.687 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 29.8 KiB, free 433.5 MiB)
23/01/20 15:56:51.687 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 433.5 MiB)
23/01/20 15:56:51.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:51172 (size: 11.8 KiB, free: 810.6 MiB)
23/01/20 15:56:51.687 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
23/01/20 15:56:51.687 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[78] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:56:51.687 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 8 tasks resource profile 0
23/01/20 15:56:51.687 dispatcher-event-loop-5 WARN TaskSetManager: Stage 13 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:56:51.687 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 31) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.702 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 32) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.702 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 33) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.702 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 34) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.718 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 35) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.718 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 810.6 MiB)
23/01/20 15:56:51.718 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 36) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 3009944 bytes) taskResourceAssignments Map()
23/01/20 15:56:51.718 Executor task launch worker for task 4.0 in stage 13.0 (TID 35) INFO Executor: Running task 4.0 in stage 13.0 (TID 35)
23/01/20 15:56:51.718 Executor task launch worker for task 0.0 in stage 13.0 (TID 31) INFO Executor: Running task 0.0 in stage 13.0 (TID 31)
23/01/20 15:56:51.718 Executor task launch worker for task 1.0 in stage 13.0 (TID 32) INFO Executor: Running task 1.0 in stage 13.0 (TID 32)
23/01/20 15:56:51.718 Executor task launch worker for task 5.0 in stage 13.0 (TID 36) INFO Executor: Running task 5.0 in stage 13.0 (TID 36)
23/01/20 15:56:51.718 Executor task launch worker for task 3.0 in stage 13.0 (TID 34) INFO Executor: Running task 3.0 in stage 13.0 (TID 34)
23/01/20 15:56:51.718 Executor task launch worker for task 2.0 in stage 13.0 (TID 33) INFO Executor: Running task 2.0 in stage 13.0 (TID 33)
23/01/20 15:56:51.718 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 810.6 MiB)
23/01/20 15:56:51.734 Executor task launch worker for task 4.0 in stage 13.0 (TID 35) INFO MemoryStore: Block rdd_65_4 stored as values in memory (estimated size 2.8 MiB, free 430.7 MiB)
23/01/20 15:56:51.734 Executor task launch worker for task 2.0 in stage 13.0 (TID 33) INFO MemoryStore: Block rdd_65_2 stored as values in memory (estimated size 2.8 MiB, free 425.0 MiB)
23/01/20 15:56:51.734 Executor task launch worker for task 1.0 in stage 13.0 (TID 32) INFO MemoryStore: Block rdd_65_1 stored as values in memory (estimated size 2.8 MiB, free 422.2 MiB)
23/01/20 15:56:51.734 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_4 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 807.7 MiB)
23/01/20 15:56:51.734 Executor task launch worker for task 3.0 in stage 13.0 (TID 34) INFO MemoryStore: Block rdd_65_3 stored as values in memory (estimated size 2.8 MiB, free 427.8 MiB)
23/01/20 15:56:51.734 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_2 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 804.9 MiB)
23/01/20 15:56:51.749 Executor task launch worker for task 0.0 in stage 13.0 (TID 31) INFO MemoryStore: Block rdd_65_0 stored as values in memory (estimated size 2.8 MiB, free 419.4 MiB)
23/01/20 15:56:51.749 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_1 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 802.1 MiB)
23/01/20 15:56:51.749 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_3 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 799.3 MiB)
23/01/20 15:56:51.749 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_0 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 796.4 MiB)
23/01/20 15:56:51.749 Executor task launch worker for task 5.0 in stage 13.0 (TID 36) INFO MemoryStore: Block rdd_65_5 stored as values in memory (estimated size 2.8 MiB, free 416.5 MiB)
23/01/20 15:56:51.749 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_65_5 in memory on 127.0.0.1:51172 (size: 2.8 MiB, free: 793.6 MiB)
23/01/20 15:56:51.761 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:51172 in memory (size: 3.6 KiB, free: 793.6 MiB)
23/01/20 15:56:56.853 Executor task launch worker for task 4.0 in stage 13.0 (TID 35) WARN BlockManager: Putting block rdd_73_4 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:56.853 Executor task launch worker for task 4.0 in stage 13.0 (TID 35) WARN BlockManager: Block rdd_73_4 could not be removed as it was not found on disk or in memory
23/01/20 15:56:56.853 Executor task launch worker for task 4.0 in stage 13.0 (TID 35) ERROR Executor: Exception in task 4.0 in stage 13.0 (TID 35)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:56:56.865 Executor task launch worker for task 5.0 in stage 13.0 (TID 36) WARN BlockManager: Putting block rdd_73_5 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:56.865 Executor task launch worker for task 5.0 in stage 13.0 (TID 36) WARN BlockManager: Block rdd_73_5 could not be removed as it was not found on disk or in memory
23/01/20 15:56:56.869 Executor task launch worker for task 1.0 in stage 13.0 (TID 32) WARN BlockManager: Putting block rdd_73_1 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:56.870 Executor task launch worker for task 1.0 in stage 13.0 (TID 32) WARN BlockManager: Block rdd_73_1 could not be removed as it was not found on disk or in memory
23/01/20 15:56:56.870 Executor task launch worker for task 5.0 in stage 13.0 (TID 36) ERROR Executor: Exception in task 5.0 in stage 13.0 (TID 36)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:56:56.871 Executor task launch worker for task 1.0 in stage 13.0 (TID 32) ERROR Executor: Exception in task 1.0 in stage 13.0 (TID 32)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:56:56.880 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 37) (127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 2977439 bytes) taskResourceAssignments Map()
23/01/20 15:56:56.880 task-result-getter-1 WARN TaskSetManager: Lost task 4.0 in stage 13.0 (TID 35) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:56:56.880 Executor task launch worker for task 6.0 in stage 13.0 (TID 37) INFO Executor: Running task 6.0 in stage 13.0 (TID 37)
23/01/20 15:56:56.880 task-result-getter-1 ERROR TaskSetManager: Task 4 in stage 13.0 failed 1 times; aborting job
23/01/20 15:56:56.881 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 13
23/01/20 15:56:56.881 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage cancelled
23/01/20 15:56:56.881 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 13 was cancelled
23/01/20 15:56:56.881 task-result-getter-3 INFO TaskSetManager: Lost task 5.0 in stage 13.0 (TID 36) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 1]
23/01/20 15:56:56.881 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 13 (sql at <unknown>:0) failed in 5.210 s due to Job aborted due to stage failure: Task 4 in stage 13.0 failed 1 times, most recent failure: Lost task 4.0 in stage 13.0 (TID 35) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:56:56.882 dispatcher-event-loop-1 INFO Executor: Executor is trying to kill task 2.0 in stage 13.0 (TID 33), reason: Stage cancelled
23/01/20 15:56:56.882 dispatcher-event-loop-1 INFO Executor: Executor is trying to kill task 6.0 in stage 13.0 (TID 37), reason: Stage cancelled
23/01/20 15:56:56.882 dispatcher-event-loop-1 INFO Executor: Executor is trying to kill task 3.0 in stage 13.0 (TID 34), reason: Stage cancelled
23/01/20 15:56:56.882 dispatcher-event-loop-1 INFO Executor: Executor is trying to kill task 0.0 in stage 13.0 (TID 31), reason: Stage cancelled
23/01/20 15:56:56.882 task-result-getter-2 INFO TaskSetManager: Lost task 1.0 in stage 13.0 (TID 32) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 2]
23/01/20 15:56:56.882 Executor task launch worker for task 6.0 in stage 13.0 (TID 37) INFO Executor: Executor killed task 6.0 in stage 13.0 (TID 37), reason: Stage cancelled
23/01/20 15:56:56.884 Executor task launch worker for task 2.0 in stage 13.0 (TID 33) WARN BlockManager: Putting block rdd_73_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:56:56.885 Executor task launch worker for task 2.0 in stage 13.0 (TID 33) WARN BlockManager: Block rdd_73_2 could not be removed as it was not found on disk or in memory
23/01/20 15:56:56.885 Executor task launch worker for task 2.0 in stage 13.0 (TID 33) INFO Executor: Executor interrupted and killed task 2.0 in stage 13.0 (TID 33), reason: Stage cancelled
23/01/20 15:56:56.888 task-result-getter-0 WARN TaskSetManager: Lost task 2.0 in stage 13.0 (TID 33) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:56:56.889 task-result-getter-1 WARN TaskSetManager: Lost task 6.0 in stage 13.0 (TID 37) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:57:25.530 Thread-1 INFO SparkContext: Invoking stop() from shutdown hook
23/01/20 15:57:25.544 Thread-1 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/01/20 15:57:25.555 dispatcher-event-loop-2 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/20 15:57:25.608 Thread-1 INFO MemoryStore: MemoryStore cleared
23/01/20 15:57:25.608 Thread-1 INFO BlockManager: BlockManager stopped
23/01/20 15:57:25.611 Thread-1 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/20 15:57:25.613 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/20 15:57:25.627 Thread-1 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f\sparkworker_9183.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2140)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:57:25.628 Thread-1 INFO SparkContext: Successfully stopped SparkContext
23/01/20 15:57:25.629 Thread-1 INFO ShutdownHookManager: Shutdown hook called
23/01/20 15:57:25.629 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4
23/01/20 15:57:25.631 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f\sparkworker_9183.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:57:25.631 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\Temp\spark-3a094d90-2d0c-4c24-a77e-26ed31e43f44
23/01/20 15:57:25.632 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f
23/01/20 15:57:25.633 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-fb538544-9a44-4b0a-8e8f-7ebbfa04aea4\userFiles-a8a45a71-0fc8-49dd-a53a-90903ef75e3f\sparkworker_9183.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/20 15:57:54.914 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:57:55.052 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.1
23/01/20 15:57:55.102 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/01/20 15:57:55.151 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/01/20 15:57:55.182 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:57:55.182 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
23/01/20 15:57:55.182 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
23/01/20 15:57:55.182 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
23/01/20 15:57:55.198 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/01/20 15:57:55.214 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
23/01/20 15:57:55.214 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/01/20 15:57:55.297 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: anthonyp
23/01/20 15:57:55.298 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: anthonyp
23/01/20 15:57:55.298 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
23/01/20 15:57:55.298 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
23/01/20 15:57:55.299 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(anthonyp); groups with view permissions: Set(); users  with modify permissions: Set(anthonyp); groups with modify permissions: Set()
23/01/20 15:57:55.431 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51994.
23/01/20 15:57:55.446 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
23/01/20 15:57:55.486 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
23/01/20 15:57:55.494 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/01/20 15:57:55.494 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/01/20 15:57:55.509 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/01/20 15:57:55.525 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\blockmgr-13aff570-a7b2-48e0-871e-9516e1d49106
23/01/20 15:57:55.541 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
23/01/20 15:57:55.556 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
23/01/20 15:57:55.556 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local]. Please check your configured local directories.
23/01/20 15:57:55.713 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/01/20 15:57:55.760 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/anthonyp/AppData/Local/R/win-library/4.2/sparklyr/java/sparklyr-master-2.12.jar at spark://127.0.0.1:51994/jars/sparklyr-master-2.12.jar with timestamp 1674259075048
23/01/20 15:57:55.823 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
23/01/20 15:57:55.823 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/01/20 15:57:55.839 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:51994/jars/sparklyr-master-2.12.jar with timestamp 1674259075048
23/01/20 15:57:55.870 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51994 after 14 ms (0 ms spent in bootstraps)
23/01/20 15:57:55.887 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:51994/jars/sparklyr-master-2.12.jar to C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d\fetchFileTemp1180152110047874634.tmp
23/01/20 15:57:55.964 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/local/spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b/userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d/sparklyr-master-2.12.jar to class loader
23/01/20 15:57:55.987 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52042.
23/01/20 15:57:55.987 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:52042
23/01/20 15:57:55.987 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/01/20 15:57:55.996 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52042, None)
23/01/20 15:57:56.012 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52042 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 52042, None)
23/01/20 15:57:56.012 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52042, None)
23/01/20 15:57:56.012 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52042, None)
23/01/20 15:57:56.288 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive') to the value of spark.sql.warehouse.dir.
23/01/20 15:57:56.294 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive'.
23/01/20 15:57:58.827 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/01/20 15:57:58.949 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/conf/hive-site.xml
23/01/20 15:57:59.236 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/anthonyp/AppData/Local/spark/spark-3.3.1-bin-hadoop2/tmp/hive
23/01/20 15:57:59.436 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 15:57:59.437 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 15:57:59.437 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 15:57:59.475 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
23/01/20 15:57:59.582 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
23/01/20 15:57:59.583 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
23/01/20 15:58:00.385 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
23/01/20 15:58:01.465 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 15:58:01.468 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
23/01/20 15:58:01.515 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
23/01/20 15:58:01.516 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@10.0.0.229
23/01/20 15:58:01.521 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
23/01/20 15:58:01.650 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
23/01/20 15:58:01.652 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
23/01/20 15:58:01.669 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/01/20 15:58:01.737 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:58:01.753 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:01.766 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
23/01/20 15:58:01.766 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: global_temp	
23/01/20 15:58:01.767 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/01/20 15:58:01.767 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:58:01.767 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:01.769 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:58:01.769 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:01.771 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:58:01.771 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:58:02.030 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:58:02.030 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:02.031 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
23/01/20 15:58:02.032 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:02.033 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
23/01/20 15:58:02.033 nioEventLoopGroup-2-2 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:58:02.772 nioEventLoopGroup-2-3 INFO HiveMetaStore: 1: get_database: default
23/01/20 15:58:02.772 nioEventLoopGroup-2-3 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:02.819 nioEventLoopGroup-2-3 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
23/01/20 15:58:02.819 nioEventLoopGroup-2-3 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
23/01/20 15:58:02.819 nioEventLoopGroup-2-3 INFO HiveMetaStore: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/01/20 15:58:02.819 nioEventLoopGroup-2-3 INFO ObjectStore: ObjectStore, initialize called
23/01/20 15:58:02.819 nioEventLoopGroup-2-3 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/01/20 15:58:02.835 nioEventLoopGroup-2-3 INFO ObjectStore: Initialized ObjectStore
23/01/20 15:58:02.835 nioEventLoopGroup-2-3 INFO HiveMetaStore: 1: get_database: default
23/01/20 15:58:02.835 nioEventLoopGroup-2-3 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_database: default	
23/01/20 15:58:02.835 nioEventLoopGroup-2-3 INFO HiveMetaStore: 1: get_tables: db=default pat=*
23/01/20 15:58:02.835 nioEventLoopGroup-2-3 INFO audit: ugi=anthonyp	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
23/01/20 15:58:03.287 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 124.2715 ms
23/01/20 15:58:03.410 nioEventLoopGroup-2-3 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:58:03.416 nioEventLoopGroup-2-3 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.004756 s
23/01/20 15:58:03.932 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 6.3869 ms
23/01/20 15:58:03.946 nioEventLoopGroup-2-3 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:58:03.957 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:58:03.958 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
23/01/20 15:58:03.958 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:58:03.959 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:58:03.961 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
23/01/20 15:58:04.005 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:58:04.037 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:58:04.037 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:52042 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:58:04.037 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
23/01/20 15:58:04.057 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:58:04.057 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/01/20 15:58:04.102 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:58:04.118 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/01/20 15:58:04.303 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1361 bytes result sent to driver
23/01/20 15:58:04.303 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 208 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:58:04.303 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/01/20 15:58:04.303 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0.332 s
23/01/20 15:58:04.319 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:58:04.319 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/01/20 15:58:04.319 nioEventLoopGroup-2-3 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0.374723 s
23/01/20 15:58:04.343 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 10.051 ms
23/01/20 15:58:04.470 nioEventLoopGroup-2-3 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KiB, free 912.3 MiB)
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.3 MiB)
23/01/20 15:58:04.470 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:52042 (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:58:04.470 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/01/20 15:58:04.470 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:58:04.470 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/01/20 15:58:04.489 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1318 bytes result sent to driver
23/01/20 15:58:04.491 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 20 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:58:04.491 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/01/20 15:58:04.491 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.021 s
23/01/20 15:58:04.492 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:58:04.492 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/01/20 15:58:04.492 nioEventLoopGroup-2-3 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.016654 s
23/01/20 15:58:06.183 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:52042 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:58:06.214 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:52042 in memory (size: 3.6 KiB, free: 912.3 MiB)
23/01/20 15:58:06.214 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 125.7 MiB, free 786.6 MiB)
23/01/20 15:58:06.333 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 782.6 MiB)
23/01/20 15:58:06.337 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:52042 (size: 4.0 MiB, free: 908.3 MiB)
23/01/20 15:58:06.339 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2_piece1 stored as bytes in memory (estimated size 4.0 MiB, free 778.6 MiB)
23/01/20 15:58:06.347 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece1 in memory on 127.0.0.1:52042 (size: 4.0 MiB, free: 904.3 MiB)
23/01/20 15:58:06.349 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2_piece2 stored as bytes in memory (estimated size 4.0 MiB, free 774.6 MiB)
23/01/20 15:58:06.350 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece2 in memory on 127.0.0.1:52042 (size: 4.0 MiB, free: 900.3 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2_piece3 stored as bytes in memory (estimated size 4.0 MiB, free 770.6 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece3 in memory on 127.0.0.1:52042 (size: 4.0 MiB, free: 896.3 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_2_piece4 stored as bytes in memory (estimated size 3.7 MiB, free 766.9 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece4 in memory on 127.0.0.1:52042 (size: 3.7 MiB, free: 892.6 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO SparkContext: Created broadcast 2 from broadcast at workerhelper.scala:104
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 40.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 69.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:52042 (size: 69.0 B, free: 892.6 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO SparkContext: Created broadcast 3 from broadcast at workerhelper.scala:105
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 248.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 219.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:52042 (size: 219.0 B, free: 892.6 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO SparkContext: Created broadcast 4 from broadcast at workerhelper.scala:106
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1320.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 501.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:52042 (size: 501.0 B, free: 892.6 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO SparkContext: Created broadcast 5 from broadcast at workerhelper.scala:107
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1928.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1033.0 B, free 766.9 MiB)
23/01/20 15:58:06.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:52042 (size: 1033.0 B, free: 892.6 MiB)
23/01/20 15:58:06.353 nioEventLoopGroup-2-3 INFO SparkContext: Created broadcast 6 from broadcast at workerhelper.scala:108
23/01/20 15:58:06.449 nioEventLoopGroup-2-3 INFO SparkContext: Starting job: collect at utils.scala:26
23/01/20 15:58:06.450 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
23/01/20 15:58:06.450 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
23/01/20 15:58:06.450 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:58:06.450 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:58:06.451 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KiB, free 766.9 MiB)
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 766.9 MiB)
23/01/20 15:58:06.454 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:52042 (size: 3.6 KiB, free: 892.6 MiB)
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/01/20 15:58:06.454 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.454 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/01/20 15:58:06.454 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1318 bytes result sent to driver
23/01/20 15:58:06.454 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 0 ms on 127.0.0.1 (executor driver) (1/1)
23/01/20 15:58:06.454 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.001 s
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/01/20 15:58:06.454 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/01/20 15:58:06.454 nioEventLoopGroup-2-3 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.015015 s
23/01/20 15:58:06.665 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 10.7252 ms
23/01/20 15:58:06.686 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 25.2065 ms
23/01/20 15:58:06.702 nioEventLoopGroup-2-3 INFO CodeGenerator: Code generated in 7.8058 ms
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 26 (sql at <unknown>:0) as input to shuffle 0
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (sql at <unknown>:0) with 8 output partitions
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (sql at <unknown>:0)
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
23/01/20 15:58:06.764 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0), which has no missing parents
23/01/20 15:58:06.802 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.8 KiB, free 766.8 MiB)
23/01/20 15:58:06.802 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 766.8 MiB)
23/01/20 15:58:06.802 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:52042 (size: 11.8 KiB, free: 892.5 MiB)
23/01/20 15:58:06.802 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
23/01/20 15:58:06.802 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[26] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
23/01/20 15:58:06.802 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
23/01/20 15:58:06.874 dispatcher-event-loop-1 WARN TaskSetManager: Stage 3 contains a task of very large size (2929 KiB). The maximum recommended task size is 1000 KiB.
23/01/20 15:58:06.874 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 3000047 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.874 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:52042 in memory (size: 3.6 KiB, free: 892.5 MiB)
23/01/20 15:58:06.874 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 2971943 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.874 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 2989468 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.874 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 3008696 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7) (127.0.0.1, executor driver, partition 4, PROCESS_LOCAL, 3013328 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8) (127.0.0.1, executor driver, partition 5, PROCESS_LOCAL, 3009944 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9) (127.0.0.1, executor driver, partition 6, PROCESS_LOCAL, 2977439 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10) (127.0.0.1, executor driver, partition 7, PROCESS_LOCAL, 3013382 bytes) taskResourceAssignments Map()
23/01/20 15:58:06.890 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/01/20 15:58:06.902 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
23/01/20 15:58:06.902 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
23/01/20 15:58:06.902 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
23/01/20 15:58:06.902 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
23/01/20 15:58:06.906 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO Executor: Running task 5.0 in stage 3.0 (TID 8)
23/01/20 15:58:06.906 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO Executor: Running task 7.0 in stage 3.0 (TID 10)
23/01/20 15:58:06.906 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO Executor: Running task 6.0 in stage 3.0 (TID 9)
23/01/20 15:58:07.002 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) INFO MemoryStore: Block rdd_13_6 stored as values in memory (estimated size 2.8 MiB, free 761.2 MiB)
23/01/20 15:58:07.002 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 2.8 MiB, free 758.3 MiB)
23/01/20 15:58:07.002 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 2.8 MiB, free 761.2 MiB)
23/01/20 15:58:07.002 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 2.8 MiB, free 752.7 MiB)
23/01/20 15:58:07.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_6 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 889.7 MiB)
23/01/20 15:58:07.016 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 2.8 MiB, free 752.7 MiB)
23/01/20 15:58:07.016 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 2.8 MiB, free 747.0 MiB)
23/01/20 15:58:07.016 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO MemoryStore: Block rdd_13_7 stored as values in memory (estimated size 2.8 MiB, free 747.0 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_4 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 886.9 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_1 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 884.1 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 881.3 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_3 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 878.4 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_7 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 875.6 MiB)
23/01/20 15:58:07.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_2 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 872.7 MiB)
23/01/20 15:58:07.020 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) INFO MemoryStore: Block rdd_13_5 stored as values in memory (estimated size 2.8 MiB, free 744.2 MiB)
23/01/20 15:58:07.021 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_5 in memory on 127.0.0.1:52042 (size: 2.8 MiB, free: 869.9 MiB)
23/01/20 15:58:07.029 Executor task launch worker for task 1.0 in stage 3.0 (TID 4) INFO CodeGenerator: Code generated in 4.5363 ms
23/01/20 15:58:07.053 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO CodeGenerator: Code generated in 17.3733 ms
23/01/20 15:58:07.053 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) INFO CodeGenerator: Code generated in 5.5458 ms
23/01/20 15:58:13.893 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Putting block rdd_21_4 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.893 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) WARN BlockManager: Block rdd_21_4 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.893 Executor task launch worker for task 4.0 in stage 3.0 (TID 7) ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 7)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:58:13.912 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Putting block rdd_21_5 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.912 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Putting block rdd_21_7 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.912 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) WARN BlockManager: Block rdd_21_5 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.912 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) WARN BlockManager: Block rdd_21_7 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.912 Executor task launch worker for task 7.0 in stage 3.0 (TID 10) ERROR Executor: Exception in task 7.0 in stage 3.0 (TID 10)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:58:13.912 Executor task launch worker for task 5.0 in stage 3.0 (TID 8) ERROR Executor: Exception in task 5.0 in stage 3.0 (TID 8)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:58:13.925 task-result-getter-0 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 7) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

23/01/20 15:58:13.925 task-result-getter-0 ERROR TaskSetManager: Task 4 in stage 3.0 failed 1 times; aborting job
23/01/20 15:58:13.925 task-result-getter-3 INFO TaskSetManager: Lost task 7.0 in stage 3.0 (TID 10) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 1]
23/01/20 15:58:13.925 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) WARN BlockManager: Putting block rdd_21_6 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.925 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) WARN BlockManager: Block rdd_21_6 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.925 dag-scheduler-event-loop INFO TaskSchedulerImpl: Cancelling stage 3
23/01/20 15:58:13.925 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage cancelled
23/01/20 15:58:13.925 Executor task launch worker for task 6.0 in stage 3.0 (TID 9) ERROR Executor: Exception in task 6.0 in stage 3.0 (TID 9)
java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)
23/01/20 15:58:13.940 dag-scheduler-event-loop INFO TaskSchedulerImpl: Stage 3 was cancelled
23/01/20 15:58:13.940 task-result-getter-1 INFO TaskSetManager: Lost task 5.0 in stage 3.0 (TID 8) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 2]
23/01/20 15:58:13.940 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (sql at <unknown>:0) failed in 7.176 s due to Job aborted due to stage failure: Task 4 in stage 3.0 failed 1 times, most recent failure: Lost task 4.0 in stage 3.0 (TID 7) (127.0.0.1 executor driver): java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:83)
	at sparklyr.WorkerApply$$anon$2.run(workerapply.scala:138)

Driver stacktrace:
23/01/20 15:58:13.940 task-result-getter-2 INFO TaskSetManager: Lost task 6.0 in stage 3.0 (TID 9) on 127.0.0.1, executor driver: java.lang.Exception (sparklyr worker rscript failure with status -1, check worker logs for details.) [duplicate 3]
23/01/20 15:58:13.940 dispatcher-event-loop-6 INFO Executor: Executor is trying to kill task 2.0 in stage 3.0 (TID 5), reason: Stage cancelled
23/01/20 15:58:13.940 dispatcher-event-loop-6 INFO Executor: Executor is trying to kill task 3.0 in stage 3.0 (TID 6), reason: Stage cancelled
23/01/20 15:58:13.940 dispatcher-event-loop-6 INFO Executor: Executor is trying to kill task 0.0 in stage 3.0 (TID 3), reason: Stage cancelled
23/01/20 15:58:13.940 dispatcher-event-loop-6 INFO Executor: Executor is trying to kill task 1.0 in stage 3.0 (TID 4), reason: Stage cancelled
23/01/20 15:58:13.940 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) WARN BlockManager: Putting block rdd_21_2 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.940 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) WARN BlockManager: Block rdd_21_2 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.940 Executor task launch worker for task 2.0 in stage 3.0 (TID 5) INFO Executor: Executor interrupted and killed task 2.0 in stage 3.0 (TID 5), reason: Stage cancelled
23/01/20 15:58:13.956 task-result-getter-0 WARN TaskSetManager: Lost task 2.0 in stage 3.0 (TID 5) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 15:58:13.971 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Putting block rdd_21_3 failed due to exception java.lang.Exception: sparklyr worker rscript failure with status -1, check worker logs for details..
23/01/20 15:58:13.971 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) WARN BlockManager: Block rdd_21_3 could not be removed as it was not found on disk or in memory
23/01/20 15:58:13.971 Executor task launch worker for task 3.0 in stage 3.0 (TID 6) INFO Executor: Executor interrupted and killed task 3.0 in stage 3.0 (TID 6), reason: Stage cancelled
23/01/20 15:58:13.987 task-result-getter-3 WARN TaskSetManager: Lost task 3.0 in stage 3.0 (TID 6) (127.0.0.1 executor driver): TaskKilled (Stage cancelled)
23/01/20 20:23:26.544 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1053)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
23/01/20 20:23:29.321 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
23/01/21 11:28:47.794 Thread-1 INFO SparkContext: Invoking stop() from shutdown hook
23/01/21 11:28:47.810 Thread-1 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
23/01/21 11:28:47.825 dispatcher-event-loop-2 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/01/21 11:28:47.888 Thread-1 INFO MemoryStore: MemoryStore cleared
23/01/21 11:28:47.888 Thread-1 INFO BlockManager: BlockManager stopped
23/01/21 11:28:47.888 Thread-1 INFO BlockManagerMaster: BlockManagerMaster stopped
23/01/21 11:28:47.904 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/01/21 11:28:47.904 Thread-1 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d\sparkworker_3468.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2140)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/21 11:28:47.904 Thread-1 INFO SparkContext: Successfully stopped SparkContext
23/01/21 11:28:47.920 Thread-1 INFO ShutdownHookManager: Shutdown hook called
23/01/21 11:28:47.920 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b
23/01/21 11:28:47.920 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d\sparkworker_3468.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
23/01/21 11:28:47.920 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\Temp\spark-a5de8cfc-7cfd-499a-af97-195c605c25b4
23/01/21 11:28:47.920 Thread-1 INFO ShutdownHookManager: Deleting directory C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d
23/01/21 11:28:47.920 Thread-1 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d
java.io.IOException: Failed to delete: C:\Users\anthonyp\AppData\Local\spark\spark-3.3.1-bin-hadoop2\tmp\local\spark-0f6d8c7d-21c0-4a50-b136-c8cf4f41254b\userFiles-c8ca91b7-d6a5-4721-91f8-1f14c788b62d\sparkworker_3468.R
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
